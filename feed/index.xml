<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://y.tsutsumi.io/feed/index.xml" rel="self" type="application/atom+xml" /><link href="https://y.tsutsumi.io/" rel="alternate" type="text/html" /><updated>2025-06-23T00:07:33+00:00</updated><id>https://y.tsutsumi.io/feed/index.xml</id><title type="html">Yusuke Tsutsumi</title><subtitle>My blog on software, productivity, and obsessively optimizing. I work at Google, ex-Zillow. Thoughts my own.</subtitle><entry><title type="html">My tips on debugging</title><link href="https://y.tsutsumi.io/debugging" rel="alternate" type="text/html" title="My tips on debugging" /><published>2025-06-07T07:00:00+00:00</published><updated>2025-06-07T07:00:00+00:00</updated><id>https://y.tsutsumi.io/debugging</id><content type="html" xml:base="https://y.tsutsumi.io/debugging"><![CDATA[<h1 id="my-tips-on-debugging">My tips on debugging</h1>

<p>Updated: 2025-06-07</p>

<p>This is a running collection of my thoughts on debugging. I’ll update these over time.</p>

<h2 id="improve-errors-minimize-print-statements">Improve errors, minimize print statements</h2>

<p>One common type of debugging is “print” style - just print the data you need at the time. Often this occurs because you don’t have enough information in the error itself:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"conflicting args"</span><span class="p">)</span>
</code></pre></div></div>

<p>Rather than add a print statement temporarily, just make the error better - it helps the next person when they come along:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s">"conflict args. Args found: </span><span class="si">{</span><span class="n">args</span><span class="si">}</span><span class="s">)
</span></code></pre></div></div>]]></content><author><name></name></author><category term="coding" /><summary type="html"><![CDATA[My tips on debugging]]></summary></entry><entry><title type="html">Result, Situation, Action: a new take on the STAR format</title><link href="https://y.tsutsumi.io/rsa" rel="alternate" type="text/html" title="Result, Situation, Action: a new take on the STAR format" /><published>2025-02-08T07:00:00+00:00</published><updated>2025-02-08T07:00:00+00:00</updated><id>https://y.tsutsumi.io/result-situation-action</id><content type="html" xml:base="https://y.tsutsumi.io/rsa"><![CDATA[<h1 id="result-situation-action">Result, Situation, Action</h1>

<p>The <a href="https://en.wikipedia.org/wiki/Situation,_task,_action,_result">STAR</a> format
of answering an interview question is very popular. But in my experience a twist
on that ends up being more effective: result, situation, then action.</p>

<p>The STAR format kind of buries the lead - it forces the interviewer into a
long-winded story and they’re not engaged because they don’t understand the
value of it. By giving them some idea of the impact that your story had (e.g. I
saved the company $XXX dollars, we reduced developer wait times by 20 minutes on
a 1-hour task), that gives the interviewer a reason to listen.</p>

<p>In addition, I find the “task” part of the story tends to be extraneous - when
you only have 30 minutes to an hour with the interviewer <em>total</em>, you need to
shave the minutes where it matters.</p>

<p>Although the whole “my task was X” may take 1 minute to explain, it’s better to just explain what you <em>did</em>.</p>

<h2 id="example">Example</h2>

<p>Result: I increased revenue for the company by XX percent.</p>

<p>Situation: In multiple customer meetings, I noticed that in the follow-up of
customers meetings, they would always mention having trouble onboarding onto
feature X.</p>

<p>Action: I wrote up a user guide, and we added a link the first time a customer
accessed the feature, as well as included it in the onboarding guide.</p>

<h2 id="summary">Summary</h2>

<p>I call this “RSA” pronounced “rizza”. Try it out!</p>]]></content><author><name></name></author><category term="coding" /><summary type="html"><![CDATA[Result, Situation, Action]]></summary></entry><entry><title type="html">Many and granular: ideal code organization in Bazel repos</title><link href="https://y.tsutsumi.io/bazel-many-and-granular" rel="alternate" type="text/html" title="Many and granular: ideal code organization in Bazel repos" /><published>2025-01-29T07:00:00+00:00</published><updated>2025-01-29T07:00:00+00:00</updated><id>https://y.tsutsumi.io/bazel-many-and-granular</id><content type="html" xml:base="https://y.tsutsumi.io/bazel-many-and-granular"><![CDATA[<h1 id="better-code-organization-in-bazel">Better code organization in bazel</h1>

<p>As part of my work on <a href="https://y.tsutsumi.io/depsaw/">depsaw</a>, I did a lot of
investigation into scenarios where we were overbuilding, and the solution for
those. Here’s some thoughts on code organization based on that exploration.</p>

<h2 id="more-granular-packages-are-better-than-fewer-packages">More granular packages are better than fewer packages</h2>

<p>The original post has <a href="https://y.tsutsumi.io/depsaw/#2-causes-and-solutions">a few scenarios
enumerated</a> of why
something is overbuilding, but I’ll repeat them here:</p>

<ol>
  <li>Too many files in a single package: this causes the package to change more
  frequently, but the dependant only needs a couple of the files.</li>
  <li>Too much functionality in a single file: there might be a file with thousands
  of lines of code, but only one function is relevant to a dependent.</li>
  <li>Unnecessary dependencies. Where a target has a dependency it doesn’t use at
all.</li>
</ol>

<p>Zooming in one (1) and (2) for a second: I think this points to a more
fundamental law about code organization in bazel: that packages should be “many
and granular”. Aside from just an incorrect declaration, the other solution to
overbuilding is basically “split the package”. Implying that if the dependencies
were granular to begin with, we would have preemptively solved overbuilding.</p>

<p>This is also outlined in the bazel <a href="https://bazel.build/configure/best-practices">best
practices</a>:</p>

<blockquote>
  <p>To use fine-grained dependencies to allow parallelism and incrementality.</p>
</blockquote>

<h2 id="a-shallow-hierarchy-is-better-than-a-deeper-one">A shallow hierarchy is better than a deeper one</h2>

<p>Although tied to the above, but still worth explicitly stating: a shallow
hierarchy is better than a deep one. For example,</p>

<pre><code class="language-mermaid">graph LR
    C --&gt; A
    C --&gt; B
    D --&gt; A
    D --&gt; B
    E --&gt; A
    F --&gt; B
</code></pre>

<p>Is better than:</p>

<pre><code class="language-mermaid">graph LR
    B --&gt; A
    C --&gt; A
    D --&gt; B
    E --&gt; B
    F --&gt; B
</code></pre>

<p>A shallow hierarchy:</p>

<ul>
  <li>Helps prevent pulling in functionality from upstream dependencies (better
depend-on-what-you-use).</li>
  <li>Makes it easier to sever and refactor dependencies (fewer layers to have to
navigate through).</li>
</ul>

<h2 id="summary">Summary</h2>

<ul>
  <li>more packages are better than fewer packages.</li>
  <li>granular, composable functionality is better than giant functionality.</li>
  <li>a shallow hierarchy of dependencies is better than a deeper one.</li>
</ul>]]></content><author><name></name></author><category term="coding" /><summary type="html"><![CDATA[Better code organization in bazel]]></summary></entry><entry><title type="html">Reflecting on 2024</title><link href="https://y.tsutsumi.io/my-year/2024" rel="alternate" type="text/html" title="Reflecting on 2024" /><published>2025-01-03T07:00:00+00:00</published><updated>2025-01-03T07:00:00+00:00</updated><id>https://y.tsutsumi.io/my-year/reflecting-on-2024</id><content type="html" xml:base="https://y.tsutsumi.io/my-year/2024"><![CDATA[<p>I’m reflecting on my personal time during 2024. A lot of my time was spent
working on things with my family that I won’t share here, but nontheless I did
make some progress with my personal goals.</p>

<h2 id="farsi">Farsi</h2>

<p>This year, I think my Farsi has gotten quite a bit better:</p>

<ul>
  <li>Conversationally I can express most things.</li>
  <li>I can watch some Farsi TV and news and get the general idea.</li>
</ul>

<p>The only video game with a Farsi translation I found is <a href="https://childrenofmorta.com/">Children of
Morta</a>: I guess one of the developers is Iranian
and wanted to get a Farsi translation in. I’m super thankful for that, so I can watch those cutscenes a few times and learn the Farsi from there.</p>

<p>The big thing I did is start listening to TV in the car regularly: it’s a good
way to reinforce my listening abilities.</p>

<p>I still take Farsi lessons weekly. For 2025, I think I’ll continue at this pace,
and loosely target being able to listen and understand Farsi TV.</p>

<h2 id="fitness-and-health">Fitness and Health</h2>

<p>I’ve continued working on fitness this year. Primarily lowering body fat,
building muscle, and lowering my apob.</p>

<p>I haven’t taken a Dexa scan since July, but my body fat actually went up at the
time compared to January: I think it was due to a two-week long trip I took to
Japan in June. I was not able to work out at all, and also walked a significant
amount of time so I was still, somewhat, in a caloric deficit.</p>

<p>That said, my weight at the end of the year is about 174 pounds. Losing roughly
4 pounds in the first half of the year to 176, and 2 pounds in the last half.
I’m not sure where my body fat is at, but likely 13% where it stood in July.</p>

<p>Interestingly I lost muscle mass across the board except for my stomach in July.
I still need to check to see if I was able to regain it or not.</p>

<p>I’ve found a good routine for a caloric deficit and overall weight loss, which
is:</p>

<ul>
  <li>400 calories daily burned at the treadmill (walking 30 minutes at 3.5mph, at a
12 degree incline).</li>
  <li>A 30 minute weightlifting workout, mixing in some crossfit-style workouts from
time to time to do some interval training.</li>
  <li>Maintaining ~1400 calories a day.</li>
</ul>

<p>I cheat on the calories regularly, so my weight is yo-yoing for now, but I’m
able to keep it between 171 and 175, and able to lose a pound a week with the
above. Given the holidays, I think this is invitable, but hoping to get back on
the wagon next year.</p>

<p>I upped my protein to 1.6g protein / kg, which I’ve read is about where the
benefits to hypertrophy level off.</p>

<p>For 2025, with a consistent technique to lose weight, I’m shifting my focus to
figure out how to build more muscle. I think there’s a lot of optimization I’m
missing out on there.</p>

<h2 id="japanese">Japanese</h2>

<p>For this year, my Japanese took a back burner. I stopped taking regular Japanese
lessons. Honestly I think to maximize those lessons, I would have to start doing
some pretty complex assignments like writing of papers and whatnot. It’s not
something I’m that interested in investing time into.</p>

<p>For now, I’ll just play video games in Japanese when I can. I have Witcher 3 and
the Tactics Ogre remake, which will be dozens of hours and are already
challenging me with new vocabulary.</p>

<h2 id="oss-aepdev">OSS: aep.dev</h2>

<p>aep.dev made a ton of progress! Don’t just take my word for it -  check out our
<a href="https://aep.dev/blog/2024-in-review/">public blog post</a> on the topic.</p>

<p>I’m very proud of the fact that we finally moved from just theoretical benefits
to the client tooling, to real UIs and clients. If you author an AEP-compliant
specification, you can get a <a href="https://github.com/aep-dev/aepcli">command line for
free</a>. We’re working on a web
<a href="https://github.com/aep-dev/aep-explorer">UI</a>, and have some prototyping of a
Terraform/OpenTofu provider as well.</p>

<p>With the progress we’ve made this year, I’m very excited about using that as a
foundation for continued progress in aep.dev in 2025. This could be the year we
really build out a full offering, and provide something compelling to adopters
of our API specification!</p>

<h2 id="goals-for-2025">Goals for 2025</h2>

<p>For 2025, my goals are still to primarily have ample time to do impromptu things
with my family. But I do have a few goals:</p>

<ul>
  <li>Get a roadmap for aep.dev</li>
  <li>Play piano 10 minutes a day. Last year, I did not learn new 5 piano pieces.
Darn! But I’ll make this my new goal for the year. My goal this year is to be
able to play piano pieces from just reading sheet music.</li>
  <li>Be able to understand persian news.</li>
  <li>Achieve 11% body fat, without losing muscle mass.</li>
</ul>]]></content><author><name></name></author><category term="2024" /><category term="reflection" /><summary type="html"><![CDATA[I’m reflecting on my personal time during 2024. A lot of my time was spent working on things with my family that I won’t share here, but nontheless I did make some progress with my personal goals.]]></summary></entry><entry><title type="html">Winning Deduckto</title><link href="https://y.tsutsumi.io/deduckto/" rel="alternate" type="text/html" title="Winning Deduckto" /><published>2024-12-31T07:00:00+00:00</published><updated>2024-12-31T07:00:00+00:00</updated><id>https://y.tsutsumi.io/deduckto</id><content type="html" xml:base="https://y.tsutsumi.io/deduckto/"><![CDATA[<h1 id="winning-deduckto">Winning Deduckto</h1>

<p>For the holidays, my kids got a game called
<a href="https://gamewright.com/product/deduckto">Deduckto</a>. It’s a cute game for 8
years and older, where each player has their own mystery suspect which consists
of a suspect (like a pig), a disguise (a mustache), and a location (the
library). The goal of the game is to be able to identify all three attributes.</p>

<p>The game works by playing cards that are also a suspect, disguise, and location,
and putting each one into piles of “yes”, where there is one or more attributes
shared by a card, or “no” where none of the attributes are shared.</p>

<p>The game is meant for children and building their reasoning ability. And for my
kids, it’s been a great way for them to exercise that skill. I usually play more
cooperatively, where I talk with my kids about what the possibilities are, and
help them find relationships they didn’t before, like the fact that a card in
the “no” pile eliminates all of the attributes as possibilities.</p>

<p>So optimal play, I’m sure, won’t be the goal for most. That said: what is the
most optimal way to play? Here’s my thoughts.</p>

<h2 id="tldr">TLDR</h2>

<p>Try to get as many pairs of cards that have a single common attribute in the
“yes” pile as possible. The strategy is:</p>

<ol>
  <li>If possible, play a card with only one common attribute with a single “yes”
card you already have.</li>
  <li>If you have no such card, play a card that shares nothing in common with any
of your yes or no cards, to find a new “yes” card. Between the two, prefer
yes (since something that matches cards you already have), then no.</li>
</ol>

<h2 id="why">Why</h2>

<p>The optimal play is the one that eliminates the most possibilities.</p>

<p>Getting a “no” will at most eliminate three possiblities: a suspect, a disguise,
and a location.</p>

<p>Getting a “yes” can, at best, validate three attributes. But in most cases, it
will validate one. One way that is done by finding a pair of cards that are
disjoint in all but one attribute, but both are yes.</p>

<p>If you find a common attribute, you immediately eliminate all the other choices
for that feature. That means you can eliminate up to 6 other possibilities in a
single turn! Much more effective than eliminate 6 possibilities with 6 cards.</p>

<p>Getting a pair of yes cards would leave one of two possibilities:</p>

<ol>
  <li>The common attribute matches the secret suspect (e.g. they both are at the
“library”).</li>
  <li>The two cards match for a different reason, and each on a separate attribute
(e.g. for a (fox,bandana,library) and a (bear,mustache,library), fox and
mustache are matching or  bear and bandana are matching).</li>
</ol>

<p>Either could be validated by having a <em>third</em> matching card that shares
attributes with one or the other. And so on.</p>

<p>Among the cards, you will have the following, in order of preference to play.</p>

<ol>
  <li>card(s) that share 2 attributes, each with one or more yes cards, if the
attributes are not yet validated.</li>
  <li>card(s) that share 1 attribute with only one yes card, that does not already
share an attribute with another yes card.</li>
  <li>card(s) that share 1 attribute with two other yes cards.</li>
  <li>card(s) that share 0 attributes with any yes cards.</li>
  <li>all other cards.</li>
</ol>

<p>The reason is:</p>

<p>1: This will validate multiple attributes simultaneously. Although rare, it is
an ideal play.</p>

<p>2: A single attribute, common with a single yes card, will help identify a
unique attribute of your suspect.</p>

<p>3: This will help confirm that the attribute shared by the other 2 cards is
indeed the card that is unique to the suspect.</p>

<p>3: The above work to validate attributes your suspect may have. But if you can’t
do that, then it’s best to find new “yes” cards. The best way to do that is to
play unique cards as much as possible, disjoint to “yes”es, but ideally also
“no”s as well.</p>

<p>Anything else is effectively useless, giving no information.</p>]]></content><author><name></name></author><category term="board-games" /><summary type="html"><![CDATA[Winning Deduckto]]></summary></entry><entry><title type="html">depsaw: analyze and stop overbuilding in bazel</title><link href="https://y.tsutsumi.io/depsaw/" rel="alternate" type="text/html" title="depsaw: analyze and stop overbuilding in bazel" /><published>2024-12-27T07:00:00+00:00</published><updated>2024-12-27T07:00:00+00:00</updated><id>https://y.tsutsumi.io/depsaw</id><content type="html" xml:base="https://y.tsutsumi.io/depsaw/"><![CDATA[<h2 id="summary">Summary</h2>

<p>Today, I’m introducing <a href="https://github.com/toumorokoshi/depsaw/">depsaw</a>: an
experimental tool that can be used to reduce overbuilding and overtesting in bazel.</p>

<p>In its current state, it is a tool that is used to analyze the dependency graph
and commit frequencies per file to produce a list of targets that could be
optimized significantly.</p>

<p>Here is an example from the <a href="https://github.com/bazelbuild/bazel">bazel</a> codebase itself:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>depsaw trigger-scores-map ~/workspace/bazel <span class="s2">"//:bazel-distfile"</span>
targets:
- name: //src/main/java/com/google/devtools/build/lib/analysis:srcs
  rebuilds: 3604
  immediate_dependents: 1
  total_dependents: 5
  score: 3604
- name: //src/test/shell:srcs
  rebuilds: 3092
  immediate_dependents: 1
  total_dependents: 4
  score: 3092
- name: //src/main/java/com/google/devtools/build/lib/bazel:srcs
  rebuilds: 2741
  immediate_dependents: 1
  total_dependents: 5
  score: 2741
- name: //src/test/java/com/google/devtools/build/lib/rules:srcs
  rebuilds: 2647
  immediate_dependents: 1
  total_dependents: 5
  score: 2647
... <span class="c"># a few thousand other lines</span>
</code></pre></div></div>

<p>This shows that <code class="language-plaintext highlighter-rouge">//src/main/java/com/google/devtools/build/lib/analysis:srcs</code>
caused 3604 rebuilds of <code class="language-plaintext highlighter-rouge">//:bazel-distfile</code> and its dependents over the history
of the repo.</p>

<p>In the future, I’d like to also introduce tooling to help automatically reduce
or split dependencies. If you want to just dive in, look at the
<a href="https://github.com/toumorokoshi/depsaw/tree/main?tab=readme-ov-file#depsaw">readme</a>
and give it a shot! If you’re interested in learning the story and design
considerations, read on.</p>

<h2 id="backstory-overbuilding-and-overtesting-downstream-targets">Backstory: overbuilding and overtesting downstream targets</h2>

<p>At Cruise, we use <a href="https://bazel.build">bazel</a> as our build system for a
significant chunk of the code base. Combined with a monorepo (where all source
code for an organization is in a single code repository), it has allowed for a
fluid experience with building and testing software. This will not be a deep
dive into bazel and its capabilities, but bazel at a high level organizes
projects in the following way:</p>

<ol>
  <li>Source <em>files</em> are consumed into buildable units known as <em>targets</em>. Each
target is generated from a <em><a href="https://bazel.build/extending/rules">rule</a></em>.</li>
  <li>Targets can be dependants for other targets, runnable as
tests, or as a generic executable (e.g. a command-line interface).</li>
  <li>Bazel runs in two phases: an analyze phase that is able to understand the
relationship between these dependencies.</li>
</ol>

<p>Bazel has rules and <a href="https://bazel.build/extending/toolchains">toolchains</a> for a
wide variety of languages, allowing intermingling of python on C/C++
dependencies (e.g. with pybind), or adding in a static file (e.g. yaml or some
binary asset) that a target depends upon.</p>

<p>Like all codebases, functionality gravitates toward a few upstream dependencies,
on which thousands or more downstream targets depend on. For example, a utility
library for wrapping shell scripts might have hundreds of thousands of
dependants.</p>

<p>To reduce the cost of building everything, all the time, build systems often
cache their results. Bazel is no exception, providing both local and <a href="https://bazel.build/remote/caching">remote
caching</a> functionality. This means that you
only rebuild a target when it, or its dependencies, actually changes.</p>

<p>As this continues, we can run into <em>overbuilding</em>, where downstream targets are
rebuliding too often, even when the code they actually depend on don’t change.
This happens due to:</p>

<ol>
  <li>Depending on only a handful of files in a target that has a large number of
files in its source files.</li>
  <li>Depending on a target which pulls in another dependency, which is not used in
your particular code path or is included erreously.</li>
</ol>

<p>So how do you solve overbuilding? That’s what this post and depsaw are all
about.</p>

<h2 id="fixing-overbuilding-and-overtesting">Fixing overbuilding and overtesting</h2>

<p>If you have a codebase where things are being overbuilt, the general workflow is
to solve that is along the lines of:</p>

<ol>
  <li>Find the targets that are causing the most rebuilds: it’s good to scope the
problem to the high-value targets.</li>
  <li>Identify why the target is contributing so much to the builds. Apply the
appropriate solution.</li>
  <li>Back to 1.</li>
</ol>

<p>Let’s dive into each of those in detail.</p>

<h3 id="1-find-the-targets-causing-the-most-rebuilds">1: Find the targets causing the most rebuilds</h3>

<p>The targets that are causing rebuilds comes down to a couple dimensions:</p>

<ol>
  <li>Invalidations of the target’s builds. Targets can invalidate frequently
because:
    <ul>
      <li>They depend on a things that also invalidate frequently.</li>
      <li>There are a frequent changes to their source files.</li>
    </ul>
  </li>
  <li>Dependants. If you have a target that hundreds or thousands of other targets
depend on, that can cascade and result in invalidating downstream targets
very frequently.</li>
</ol>

<p>We can create a scoring like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>score(target) = total_recursive_dependants(target) * len(commits_to_build(target))
</code></pre></div></div>

<p>The score is very high if there are a lot of dependents, or the target itself is
changing very frequently. This is actually very similar to the <a href="https://www.youtube.com/watch?v=k4H20WxhbsA&amp;t=534s">metrics that
Spotify used to analyze their overbuilding for their mobile
apps</a>.</p>

<p>Here’s a table to help you get a sense of the score:</p>

<table>
  <thead>
    <tr>
      <th>score</th>
      <th>dependents</th>
      <th>average_distinct_commits_per_file</th>
      <th>num_input_files</th>
      <th>commits_dependencies_built</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1000</td>
      <td>100</td>
      <td>1</td>
      <td>10</td>
      <td>0</td>
    </tr>
    <tr>
      <td>501</td>
      <td>10</td>
      <td>1</td>
      <td>1</td>
      <td>50</td>
    </tr>
    <tr>
      <td>500</td>
      <td>10</td>
      <td>10</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <td>200</td>
      <td>2</td>
      <td>1</td>
      <td>100</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>Targets that have a lot of dependents will score higher, since the invalidate
multiple targets.</li>
  <li>Targets that have a lot of rapidly input files will score higher.</li>
  <li>Targets that have a fair number of dependents, and depend on a fair number of
targets, will score higher.</li>
  <li>Targets that have a fair number of dependents, as well as have a high number
of files modified, will score higher.</li>
</ul>

<p>Using depsaw, you can get these scores with the following, running it against a
git repository using bazel:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">TARGET</span><span class="o">=</span>YOUR_TARGET_HERE
depsaw trigger-scores-map <span class="si">$(</span><span class="nb">pwd</span><span class="si">)</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TARGET</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--format</span><span class="o">=</span>csv <span class="nt">--since</span> 2024-11-01 <span class="nt">--deps-file</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DEPS_FILE</span><span class="k">}</span><span class="s2">"</span> <span class="o">&gt;</span> /tmp/deps.csv
</code></pre></div></div>

<p>Here’s some rough pseudocode of the algorithm:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">commits_to_build</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
   <span class="n">commits</span> <span class="o">=</span> <span class="n">commits_that_modified_files</span><span class="p">(</span><span class="n">targets</span><span class="p">.</span><span class="n">input_files</span><span class="p">)</span>
   <span class="k">for</span> <span class="n">dep</span> <span class="ow">in</span> <span class="n">target</span><span class="p">.</span><span class="n">dependencies</span><span class="p">:</span>
      <span class="n">commits</span> <span class="o">=</span> <span class="n">commits</span> <span class="o">|</span> <span class="n">commits_to_build</span><span class="p">(</span><span class="n">dep</span><span class="p">)</span>
   <span class="k">return</span> <span class="n">commits</span>
</code></pre></div></div>

<p>Basically, looking at all the commits that modified the input files of your
target, and taking the union of that and all the commits that would have
triggered a build of a dependency.</p>

<p>This is also recursive - which means that as you build the list of commits for
one target, you can easily build it for all the targets it depends on at the
same time.</p>

<p>We can build this algorithm by first getting the list of modified files in git,
per commit, via a command like:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="nt">--numstat</span> | <span class="nb">awk</span> <span class="s1">'/^[0-9-]+/{ print $NF}'</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
</code></pre></div></div>

<p>And use the information around dependencies extracted from bazel:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bazel query <span class="s2">"deps(//...)"</span> <span class="nt">--output</span> streamed_jsonproto<span class="sb">`</span>
</code></pre></div></div>

<h3 id="2-causes-and-solutions">2: Causes and solutions</h3>

<p>Fundamentally, overbuilding comes from depending on targets that are too big,
for one reason or another.</p>

<h4 id="too-many-files-in-a-single-package">too many files in a single package</h4>

<p>In this case, there are too many files that are grouped in the same target, such
that targets must now depend on that single mega-target, rebuilding all
dependants.</p>

<p>Solution: files should be split up into more granular targets. Using a code
search tool to find the references to various files and imports. Analyzing those
would help you determine which refactors are easiest by hand.</p>

<h4 id="too-much-functionality-in-a-single-file">too much functionality in a single file</h4>

<p>In this case, there is a single file that is depended on by too many targets.</p>

<p>Solution: separate the file into multiple other files, then split those up into
separate targets. Modify dependents to use the split dependency. Using a code
analysis tool, you can see which functions are used the most, then factor those
into separate targets.</p>

<h4 id="unnescessary-dependencies">unnescessary dependencies</h4>

<p>In this case, there are dependencies that are completely unnescessary.
Anecdotally I think this is overexagerrated as an issue, but it is possible
without some proper pruning that a target that was previously relevant no longer
is.</p>

<p>Solution: remove that target.</p>

<h2 id="conclusions-and-other-thoughts">conclusions and other thoughts</h2>

<p>This tooling has already been helpful: I’ve found opportunities to factor
dependencies of some of my targets by 30%!</p>

<p>The above process is a start, but, like depsaw, there’s a lot more to do to make
eliminating overbuilding a more automated and simpler exercise. I will probably
have a follow-up post at some point when I have some better insights. If you
have some ideas, please join the conversation at the bottom or contact me!</p>

<p>In the meantime, here’s some other musings:</p>

<h3 id="considering-sibling-dependencies-for-more-score-accuracy">Considering sibling dependencies for more score accuracy</h3>

<p>Even the score above is a bit naive - it ignores the fact that there are common
dependencies that would be pulled in via other means anyway. for example, a
utility library may be pulled in even if a different dependent is removed:</p>

<pre><code class="language-mermaid">graph LR
    A[A]
    B[B]
    C[C]
    D[D]

    A --&gt; B
    A --&gt; C
    B --&gt; D
    B --&gt; E
    C --&gt; D
</code></pre>

<p>In this case, removing B from A wouldn’t actually prevent rebuilds of Target A
when D changes, since it would still be pulled in through B and C. So the value
in removing a dependency would be more accurate if it included a way to measure
the reduction in builds by removing B, and thereby removing the dependencies
that are unique to it (like E).</p>

<p>For now, this can be emulated in depsaw by first re-running depsaw before and
after removing a dependency - this will tell you what the actual net difference
would be in eliminating that specific dependent from the graph.</p>

<h2 id="bazel-is-amazing">Bazel is amazing</h2>

<p>Although separate from the point of this post, bazel is an extremely powerful
tool. I would argue that for a monorepo to succeed, you need <em>some</em> sort of
system that is used to define the complex relationship between software units,
and is able to give you descriptive answers about these relationships. To that
end, bazel provides the <a href="https://bazel.build/query/guide">query</a> command. You
can use it to answer the following questions, and more:</p>

<table>
  <thead>
    <tr>
      <th>question</th>
      <th>bazel query</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>What targets does my code depend on?</td>
      <td><code class="language-plaintext highlighter-rouge">bazel query "deps(//foo)"</code></td>
    </tr>
    <tr>
      <td>What targets depend on the code I’m working on?</td>
      <td><code class="language-plaintext highlighter-rouge">bazel query --infer_universe_scope "rdeps(//..., //foo)"</code></td>
    </tr>
    <tr>
      <td>Why does foo depend on bar?</td>
      <td><code class="language-plaintext highlighter-rouge">bazel query "somepath(//foo, //bar)"</code></td>
    </tr>
    <tr>
      <td>What are the test targets that depend on me?</td>
      <td><code class="language-plaintext highlighter-rouge">bazel query "tests(//...) intersect rdeps(//..., //foo)"</code></td>
    </tr>
  </tbody>
</table>

<p>These types of queries are critical to identifying common build problems, including:</p>

<ul>
  <li>overbuilding: rebuilding targets that are not needed.</li>
  <li>overtesting: testing downstreams that are not actually affected by your change.</li>
  <li>identifying how an extraneous target is pulled into your dependencies.</li>
</ul>]]></content><author><name></name></author><category term="coding" /><category term="bazel" /><summary type="html"><![CDATA[Summary]]></summary></entry><entry><title type="html">Design patterns for multi-organization project management</title><link href="https://y.tsutsumi.io/multi-org-project-planning/" rel="alternate" type="text/html" title="Design patterns for multi-organization project management" /><published>2024-12-12T07:00:00+00:00</published><updated>2024-12-12T07:00:00+00:00</updated><id>https://y.tsutsumi.io/multi-org-project-planning</id><content type="html" xml:base="https://y.tsutsumi.io/multi-org-project-planning/"><![CDATA[<h1 id="design-patterns-for-organizing-multi-organization-projects">Design patterns for organizing multi-organization Projects</h1>

<p>Recently, I needed to help plan a project that spanned across dozens of teams,
as wel as product areas and VPs. My task was planning my team’s deliverables,
but to do so, there were multiple pieces of information that one had to consider,
including:</p>

<ul>
  <li>Estimates on the work my team would perform.</li>
  <li>Timelines of our dependencies, and the dependencies of my team’s dependencies.</li>
  <li>Relationships between these dependencies.</li>
  <li>Stack ranking based on business impact.</li>
</ul>

<p>The process was quite taxing, resulting in quarterly planning where we had to
dig up all the context from previous quarters, find outdated docs, and go
through a multi-day effort to get this information presentable to the senior
leadership team.</p>

<p>From that, I’ve been working on some patterns and processes, built on our
existing project management tooling, make it easier to produce these roadmaps
and extract information.</p>

<h2 id="these-patterns-work-in-most-issue-trackers">These patterns work in most issue trackers</h2>

<p>I left this blog post conceptual intentionally: it’s because these are <em>design
patterns</em>: ideas that can, for the most part, be applied to any issue tracking
tool (Jira, Smartsheet, an in-house tracker).</p>

<p>Although a custom tracker may be written for this purpose, I think that these
ideas are actually more useful as design patterns. Organizations almost always
have decided on their project tracker of choice, and it’s impractical, if not
infeasible, to replace that with a bespoke solution.</p>

<p>It’s much simpler to layer these patterns on top of existing trackers, allowing
this project structure to leverage the knowledge in the issue tracker, rather
than duplicating it.</p>

<h2 id="the-patterns">The Patterns</h2>

<h3 id="a-structured-graph-of-tasks">A structured graph of tasks</h3>

<p>I’ve seen attempts to manage large project planning in long-form documents, but
once execution has begun, the individual projects and dependencies themselves
are best off in a data structure: in particular, it should be possible to
represent the tasks themselves as nodes in an acyclic graph.</p>

<p>This type of structure allows for multiple use cases, including:</p>

<ul>
  <li>Attaching common metadata to each node (like acceptance criteria, business impact).</li>
  <li>Extracting the delivery date of a node based on the delivery dates of parent
nodes, and including the effort estimate of the current one.</li>
  <li>Visualization (e.g. gantt or graph style), helping one see what the real
dependencies are.</li>
  <li>Traversing the graph to find issues that apply to a particular category (team,
org, product area)</li>
</ul>

<h3 id="tagging-over-hierarchical-structure">Tagging over hierarchical structure</h3>

<p>Although it’s common to enforce a hierarchical structure on data (e.g. issues by
team), I think tagging (e.g. Jira labels) ends up being a more useful approach.</p>

<p>Especially with tasks, there are so many different consumers that choosing a
single structure certainly will not work for all of them. Consider:</p>

<ul>
  <li>The individual contributor who just wants to look at their issues, and maybe
their teams.</li>
  <li>The manager who wants to look at all projects for their team.</li>
  <li>The director, who wants to look at projects for their team, and possibly
others that they depend on.</li>
  <li>The project manager, who wants to see all tasks that pertain to their project,
regardless of the individual or team executing that task.</li>
</ul>

<p>This, combined with products moving teams and teams moving organizations,
creates change that makes organizational hierarchy at minimum a brittle choice.</p>

<p>With tagging, along with a convention around those, it should be very easy to
create new roadmaps (just add a new tag to all relevant issues), add one-off
issues to a view for the team or organization.</p>

<h3 id="spreadsheets-for-easy-editing">Spreadsheets for easy editing</h3>

<p>At Google, we had a giant table for bugs (likely implemented as multiple tables with foreign keys for custom fields) called buganizer. You can see a glimpse of what it looks like at https://issuetracker.google.com/issues.</p>

<p>A developer wrote a tool that would do a bidirectional sync to a Google sheet,
thereby allowing us to:</p>

<ol>
  <li>Easily review the data and fields in a data dense format.</li>
  <li>Visualize roadmaps</li>
  <li>Copy-paste the spreadsheet content into documents or presentations with
leadership.</li>
  <li>Modify the fields quickly for project planning.</li>
  <li>Add new issues as we found dependencies or tasks missing.</li>
</ol>

<p>This tool was absolutely amazing - it overcame the friction of mass
modification and at-a-glance visualization.</p>

<h3 id="metadata-to-attach-a-node">Metadata to attach a node</h3>

<p>This is not a design pattern per se, but there are often specific fields in
projects that I’ve found to be very useful in roadmapping discussions. Those
are:</p>

<ul>
  <li>The business impact of the milestone: senior leadership will often ask about
the cost-benefit of lowering the priority of specific tasks, and it’s helpful
to understand why this is valuable.</li>
  <li>Acceptance criteria: a good practice regardless of this post, but it’s
valuable to be crystal clear on <em>what</em> you’re planning on delivering, and how
to validate it has been delivered. It often discovers gaps in understanding or
expectations.</li>
  <li>A target delivery date: if there is a hard due date, it’s valuable to specify
that.</li>
  <li>An effort or wall time estimate, in a unit of time: this helps you calculate
the actual time it would take to deliver something, based on the target date
of a tasks’s dependencies.</li>
</ul>

<h3 id="specify-a-target-date-or-calculate-based-on-dependencies">Specify a target date, or calculate based on dependencies.</h3>

<p>A big issue with cross-organizational planning is figuring out how long it will
actually take to deliver something. In an ideal model, the actual delivery
date of something is the sum of the duration of current task, and the sum or the
delivery dates of all of the upstream dependencies that will take the longest.</p>

<p>Therefore, two pieces of information are necessary to calculate such a date:</p>

<ul>
  <li>The duration of the actual task (also known as effort, cost, or other names).</li>
  <li>The estimated delivery date. for example, an external dependency on a vendor,
or hardware with target date at which it will finish being constructed. These
commitments are generally dates, not based on some effort estimate.</li>
</ul>

<h3 id="make-project-trackers-fast">Make project trackers fast</h3>

<p>The biggest killer to project management trackers is the speed or friction it
takes to update them. If changing a single field requires five steps, or a page
load takes a long time, those will both completely disincentivize people to fill
things in as they go. Speed is a common reason I’ve heard, discussing the ideas
in this blog post with colleagues.</p>

<p>Due to similar friction I’ve faced with documents anod knowledge bases, I just
keep a bunch of markdown document in a folder for my notes. I opened it with
VSCode so I can easily jot down notes - this is vastly faster than any web-based
solution I’ve found, and I’m more likely to take good notes as a result.</p>

<h2 id="existing-challenges">Existing Challenges</h2>

<p>These patterns above provide a great structure for organizing this knowledge.
However, this alone is not a complete solution for a well organized project.</p>

<p>I’ve enumerated some of the challenges below.</p>

<h3 id="keeping-task-metadata-up-to-date">Keeping task metadata up to date</h3>

<p>Like any semi-automated system, the above is only valuable if the data is up to
date. In my experience, individual contributors like doing the work, but do not
like rotely filling in updates in project trackers.</p>

<p>Some patterns I’ve seen work, albeit sub-optimal:</p>

<ul>
  <li>Have a single project manager be responsible for ensuring tickets are up to
date. Have a regular sync meeting where individuals give updates and update
the project tracker live.</li>
  <li>Communal updates: whoever happens to ask the question also helps update the
tickets. This is not 100% effective, but does ensure that some updates occur.</li>
  <li>Have a dedicated time, with a program / project manager as a driver, to ask
everyone to update their issues.</li>
  <li>Make it so that the issues are the <em>only</em> way to update management on the
progress of a task: the forcing function will build the habit.</li>
</ul>

<p>Again, none of these are completely effective, but do help.</p>

<h3 id="enabling-deeper-roadmap-discussions">Enabling deeper roadmap discussions</h3>

<p>One reason I believe people gravitate toward ad-hoc planning documents is
because of how the document format (with some commenting infrastructure) allows
for great long-form discussion.</p>

<p>Task tracking is traditionally quite bad at this - you can’t go comment on a
specific aspect of an issue (e.g. one or two lines in it’s description), it’s
hard to see the project overall without going to some other format like a
spreadsheet, which may not sync data back upstream.</p>

<p>At some point, project trackers should start to support this use case.</p>

<h2 id="other-thoughts">Other thoughts</h2>

<h3 id="issue-tracker-should-use-a-global-id-not-namespace-by-project">Issue tracker should use a global id, not namespace by project</h3>

<p>Issue trackers like Jira namespace their issues with a project space (e.g.
PRJ-001). I think a single global id is better, perhaps a sequential,
monotonically increasing integer (e.g. Google buganizer). The metadata for which
project an issue belongs to can live in some other field.</p>

<p>The reasoning is:</p>

<ul>
  <li>It’s easy to move issues from one team to another: links don’t break as
renames happen, you don’t need to keep a table of old ids on the server side.</li>
  <li>It’s straightforward to link issues to another: you don’t need to know which
project it was in.</li>
  <li>It simplifies any linking metadata, to have all issues in the same format
(e.g. pattern matching for APIs and what not).</li>
</ul>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>I’ll be updating this periodically with some more thoughts, but I’d love to hear
feedback on these patterns if you try them, or let me know about one what works
for you!</p>]]></content><author><name></name></author><category term="coding" /><category term="project-management" /><summary type="html"><![CDATA[Design patterns for organizing multi-organization Projects]]></summary></entry><entry><title type="html">AEPCLI’s design decisions</title><link href="https://y.tsutsumi.io/aepcli-design/" rel="alternate" type="text/html" title="AEPCLI’s design decisions" /><published>2024-10-22T07:00:00+00:00</published><updated>2024-10-22T07:00:00+00:00</updated><id>https://y.tsutsumi.io/aepcli-thoughts</id><content type="html" xml:base="https://y.tsutsumi.io/aepcli-design/"><![CDATA[<h1 id="aepclis-design-decisions">aepcli’s design decisions</h1>

<h2 id="background">Background</h2>

<p>In my spare time, I work on <a href="https://aep.dev/">aep.dev</a>, an resource-oriented
API design specification. We’ve done a lot of work around standarization, like
<a href="https://aep.dev/121/">updating guidance on resource-oriented design</a>, fleshing
out standard
<a href="https://en.wikipedia.org/wiki/Create,_read,_update_and_delete">CRUDL</a> methods, and design patterns.</p>

<p>I wanted to really prove out that those patterns and consistency could be used
to create powerful clients, so I’ve been working on
<a href="https://github.com/aep-dev/aepcli">aepcli</a>: a command-line interface to APIs
that can consume AEP-compliant HTTP+JSON APIs.</p>

<p>I’ve had some design musings as I’ve been writing it, and I wanted to expand on
some here.</p>

<h2 id="installing-aepcli">Installing aepcli</h2>

<p>If you’d like to follow along (<em>warning</em>: it is a very early alpha as of
2024-10-19), you can install aepcli yourself.</p>

<p>See <a href="https://github.com/aep-dev/aepcli">the readme</a> for the latest instructions,
but as of the moment the installation method is a <code class="language-plaintext highlighter-rouge">go install</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>go <span class="nb">install </span>github.com/aep-dev/aepcli/cmd/aepcli@latest
</code></pre></div></div>

<h2 id="overall-design">Overall design</h2>

<p>aepcli is heavily inspired by
<a href="https://kubernetes.io/docs/reference/kubectl/">kubectl</a> - itself a command-line
interface that is able to interact with a heterogenous collection of resources (those exposed by the Kubernetes API server). It has been a great reference when designing aepcli.</p>

<h2 id="consuming-an-openapi-definition">Consuming an OpenAPI definition</h2>

<p>aepcli does not need to re-invent the wheel and use new API document syntax -
<a href="https://spec.openapis.org/oas/latest.html">The OpenAPI Specification</a> is
descriptive enough (with the appropriate
<a href="https://aep.dev/4/#annotating-resource-types">extensions</a>) to describe the
resources and operations supported.</p>

<p>This is also similar to how kubectl works - reading and caching an OpenAPI
definition exposed by the Kubernetes api server. For aepcli, the location of the
definition is required, so the path is first positional argument, no matter the
command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aepcli https://bookstore.example.com/openapi.json publishers list
</code></pre></div></div>

<p>The first argument accepts either a URL, or a local file path: this is helpful
in the situation where the API itself does not expose an OpenAPI definition, and
you need to write one yourself. Or better yet, generate one with
<a href="https://github.com/aep-dev/aepc">aepc</a>!</p>

<h2 id="adding-a-config-file">Adding a config file</h2>

<p>It’s a little cumbersome to add configuration for aepcli every time. In
addition, it doesn’t look particularly elegant to include a URL/filename on
every invocation.</p>

<p>Kubectl has the concept of a <a href="https://kubernetes.io/docs/reference/kubectl/quick-reference/#kubectl-context-and-configuration">context</a>, which helps configure it to the appropriate API server. This allows kubectl to have a one-to-many relationship, being able to operate on multiple different api servers.</p>

<p>So what if we could do that with aepcli? aepcli supports a config file, located at <code class="language-plaintext highlighter-rouge">$HOME/.config/aepcli/config.toml</code> for Linux. You can write something like this:</p>

<div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[apis.roblox]</span>
<span class="py">openapipath</span> <span class="p">=</span> <span class="s">"openapi/roblox.json"</span> <span class="c"># relative paths are taken from the `$HOME/.config/aepcli` directory.</span>
<span class="py">headers</span> <span class="p">=</span> <span class="p">[</span>
    <span class="py">"x-api-key</span><span class="p">=</span><span class="err">${ROBLOX_API_KEY}</span><span class="s">" # add your api key here.</span><span class="err">
</span><span class="p">]</span>
</code></pre></div></div>

<p>And aepcli will let you easily refer to that API by it’s name:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aepcli roblox <span class="nb">users </span>get <span class="k">${</span><span class="nv">USER_ID</span><span class="k">}</span>
<span class="o">{</span>
  <span class="s2">"path"</span>: <span class="s2">"users/</span><span class="k">${</span><span class="nv">USER_ID</span><span class="k">}</span><span class="s2">"</span>,
  <span class="s2">"name"</span>: <span class="s2">"NAME"</span>,
  <span class="s2">"about"</span>: <span class="s2">""</span>,
  <span class="s2">"locale"</span>: <span class="s2">"en_us"</span>,
  <span class="s2">"premium"</span>: <span class="nb">false</span>,
  <span class="s2">"idVerified"</span>: <span class="nb">false</span>
<span class="o">}</span>
</code></pre></div></div>

<p>This makes support of a new API very easy - just write the appropriate entry in
your config, and you’re done!</p>

<p>This one-to-many CLI opens new use cases that other, bespoke CLIs cannot - like
using two APIs together. If you need a user id from an authentication provider,
and want to use that to do a lookup in some other service, you can do something
like:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">USERNAME</span><span class="o">=</span><span class="si">$(</span>aepcli auth-service get <span class="nb">users </span>foo | jq .username<span class="si">)</span>
aepcli docs-service list documents <span class="nt">--user</span><span class="o">=</span><span class="k">${</span><span class="nv">USERNAME</span><span class="k">}</span>
</code></pre></div></div>

<h2 id="client-side-dynamicism-over-code-generation">client-side dynamicism over code generation</h2>

<p>This point is more nuanced - but aepcli explicity chose to generate the CLI
based on an API description schema, instead of opting toward a code-generated
client.</p>

<p>From my time working at cloud companies, a common issue customers encountered
was with upgrading clients. Whether it was a command-line interface, Terraform
provider or SDK, customers would often have to go through painful upgrades to
use new fields exposed in the resources, since those clients were code-generated or hand-written and
only knew about the fields that the API exposed at the time it was authored.</p>

<p>There are multiple reasons why, in a worst case scenario, these upgrades would take months:</p>

<ul>
  <li>Security review.</li>
  <li>Other executive approvals.</li>
  <li>Waiting for a centralized platform team to perform the update, who often have
limited bandwidth due to serving requests across the whole company.</li>
  <li>A change in the client for a separate resource being backwards-incompatible,
requiring updating usages of that other resource to upgrade.</li>
</ul>

<p>These delays are harmful to both sides: inaccessible features for the consumer
and lost revenue for the service provider.</p>

<p>aepcli is fully dynamic - to use a new field, you don’t need to update any
<em>binaries</em> - you just update the OpenAPI document, which is completely in the
control of the consumer. Do you want access to a new field? Just add it to your
local copy of the OpenAPI document.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Although these are some of the big design considerations, there’s dozens of
smaller ones that I’m sure I’ll hash over at some point. If you have ideas or suggestions, please share them! File an issue over at <a href="https://github.com/aep-dev/aepcli/issues">aepcli</a>, or <a href="/about#contact">reach out to me</a>!</p>]]></content><author><name></name></author><category term="coding" /><summary type="html"><![CDATA[aepcli’s design decisions]]></summary></entry><entry><title type="html">Getting mp4s from Steam’s Game Recordings</title><link href="https://y.tsutsumi.io/reading-steam-game-recordings" rel="alternate" type="text/html" title="Getting mp4s from Steam’s Game Recordings" /><published>2024-07-11T07:00:00+00:00</published><updated>2024-07-11T07:00:00+00:00</updated><id>https://y.tsutsumi.io/reading-steam-game-recordings</id><content type="html" xml:base="https://y.tsutsumi.io/reading-steam-game-recordings"><![CDATA[<h2 id="the-punchline">The Punchline</h2>

<p>If you want to cut to the chase, here’s how you can get your stream recording to create a video if the UI isn’t working:</p>

<ol>
  <li>Navigate to your gamerecording/video directory (under <code class="language-plaintext highlighter-rouge">.local/share/Steam/userdata/{id}/gamerecordings/video</code>).</li>
  <li>Find the recording you’re looking for (it’s prefixed by date).</li>
  <li>Run: <code class="language-plaintext highlighter-rouge">ffmpeg -i session.mpd -c copy out.mp4</code></li>
</ol>

<p>And you’re done! There’s <code class="language-plaintext highlighter-rouge">out.mp4</code>.</p>

<h2 id="the-story">The story</h2>

<p>Steam recently came out with their <a href="https://store.steampowered.com/gamerecording">Game Recording</a> feature, which is absolutely amazing! I love the ability to be able to take videos and share them.</p>

<p>I’ve been using it to record videos of <a href="https://childrenofmorta.com/">Children of Morta</a> in Farsi, and watch the videos later as practice for learning the language. To do so, I like to export my videos to disk, and upload them privately to my youtube account.</p>

<p>But sometimes, the UI doesn’t work as expected, and I can’t download the video. So what do you do?</p>

<p>After some spelunking, I came up with the <a href="#the-punchline">instructions above</a>. The long and the short of it is: steam records your game as a stream, using the <code class="language-plaintext highlighter-rouge">.m4s</code> format, and puts the stream information into <code class="language-plaintext highlighter-rouge">session.mpd</code>.</p>

<p>Luckily, .mpd is a native format supported by <code class="language-plaintext highlighter-rouge">ffmpeg </code> for input, so all you need to do is run ffmpeg!</p>

<p>That’s it! Happy clipping.</p>]]></content><author><name></name></author><category term="steam" /><category term="coding" /><summary type="html"><![CDATA[The Punchline]]></summary></entry><entry><title type="html">Reflecting on 2023</title><link href="https://y.tsutsumi.io/my-year/2023" rel="alternate" type="text/html" title="Reflecting on 2023" /><published>2023-12-31T07:00:00+00:00</published><updated>2023-12-31T07:00:00+00:00</updated><id>https://y.tsutsumi.io/my-year/reflecting-on-2023</id><content type="html" xml:base="https://y.tsutsumi.io/my-year/2023"><![CDATA[<p>Another year, another reflection to summarize 1%+ of my life.</p>

<h2 id="japanese">Japanese</h2>

<p>I think my Japanese has reached a plateau, but it’s something I’m comfortable
with for now. The biggest gap is in my vocabulary - I’m still looking up words
in a dictionary every page I read a book or a more mature manga.</p>

<p>But whenever I play video games, I do it in Japanese! That’s a pretty good
benchmark for me, and helps me keep practicing my Japanese aside from my weekly
30 minutes lessons.</p>

<h2 id="farsi">Farsi</h2>

<p>My Farsi has not developed significantly since last year. I’m just on a slow,
steady trajectory of reading one page at a time.</p>

<p>I did pick up one of the stories I read last year and tried it again, and I was
able to get through most of it by myself! In addition, I am able to have <em>some</em>
conversation with my in-laws. So despite the relatively slow progress I’m making
<em>sufficient</em> progress to be satisfied.</p>

<p>Next year though, I’d like to invest more in my Farsi - get to the point where I
can read a good chunk of literature without help from my teacher.</p>

<h2 id="fitness-and-health">Fitness and Health</h2>

<p>I focused heavily on fitness this year, similar to the tail end of last year.</p>

<p>I have yet to do my Dexa scan for end of 2023, but I sit at roughly 180lbs. My
Dexa scan in April showed I had lost 12 pounds of body fat and gained 6 pounds
of muscle since October 2022 - not bad at all for six months!</p>

<p>My second half of the year wasn’t as aggressive - I lost 2 pounds, hopefully fat
but January we will see.</p>

<p>It’s been grueling to get there - my diet now consists of one proper meal a day
(dinner), with protein and huel shakes in between to provide 80 grams of
protein. Between that and soy lattes, I get at minimum 90 grams of protein
before dinner or snacks. That’s putting me at roughly 1.2+ g protein / kg of
body weight, which is less than what most recommend for building muscle mass,
but I haven’t seen much of an issue.</p>

<p>Next year my goal is to stick my diet a bit more, and achieve 12% body fat or
less. Once that happens I think I’ll try to maintain my weight and start
focusing on other things.</p>

<h2 id="zone-2-on-the-treadmill">Zone 2 on the treadmill</h2>

<p>I’ve been struggling to get more Zone 2 exercise into my routine - basically 30+
minutes of my heart rate at 70%-80% of my max heart rate.</p>

<p>This year I found something that works for me - playing videogames on the
treadmill!</p>

<p>I’ve been playing an RPG that keeps me engaged - Persona 4 has worked really
well for me. It also helps that it’s a long RPG, with 100+ hours to beat it.</p>

<p>With that I’ve been able to clear 30 minutes at a 12% incline and 4 miles per
hour without issue, although I don’t get past 45 very often (too late at night
or just get tired of it).</p>

<h2 id="oss-contributions">OSS Contributions</h2>

<p>Since I’ve left Google as TL of API design, I’ve been working on a fork called
https://aep.dev/. It’s been an interesting ride, discussing API design with API
leads at Roblox, IBM, Netflix, and Microsoft.</p>

<p>I built a prototype protobuf generator as part of my work, which was a fun
coding side project. Hopefully in 2024 we’ll see more established and some parts
of the spec entering production use.</p>

<h2 id="random-other-things">Random other things</h2>

<ul>
  <li>My vscode PR was completed by someone else! <a href="https://github.com/microsoft/vscode/issues/6966">awesome, this means I can finally
translate my emacs keybindings
over</a>.</li>
</ul>

<h2 id="goals-for-2024">Goals for 2024</h2>

<p>Similar to 2023, my 2024 goals are conservative - I’d like to focus on my family
and that means all of my afternoons and a good chunk of my evenings are working
on things relative to them.</p>

<p>But among my goals, they are:</p>

<ul>
  <li>Be able to read a Farsi book and understand most of the story (a movie may be
too hard for me).</li>
  <li>Learn to play 5 new pieces on the piano.</li>
  <li>Built a foundational knowledge of machine learning and abstract math.</li>
</ul>]]></content><author><name></name></author><category term="2023" /><category term="reflection" /><summary type="html"><![CDATA[Another year, another reflection to summarize 1%+ of my life.]]></summary></entry></feed>