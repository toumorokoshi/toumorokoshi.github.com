<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://y.tsutsumi.io/feed/index.xml" rel="self" type="application/atom+xml" /><link href="https://y.tsutsumi.io/" rel="alternate" type="text/html" /><updated>2025-07-26T00:05:24+00:00</updated><id>https://y.tsutsumi.io/feed/index.xml</id><title type="html">Yusuke Tsutsumi</title><subtitle>My blog on software, productivity, and obsessively optimizing. I work at Google, ex-Zillow. Thoughts my own.</subtitle><entry><title type="html">Setting up a streaming gaming Ubuntu PC for sunshine/moonlight</title><link href="https://y.tsutsumi.io/ubuntu-sunshine/" rel="alternate" type="text/html" title="Setting up a streaming gaming Ubuntu PC for sunshine/moonlight" /><published>2025-07-18T07:00:00+00:00</published><updated>2025-07-18T07:00:00+00:00</updated><id>https://y.tsutsumi.io/setting-up-moonlight-ubuntu</id><content type="html" xml:base="https://y.tsutsumi.io/ubuntu-sunshine/"><![CDATA[<h1 id="setting-up-a-streaming-gaming-ubuntu-pc-for-moonlight">Setting up a streaming gaming Ubuntu PC for moonlight</h1>

<p>I’ve been working on building a new streaming gaming PC (that ordeal I will save
for a future blog post), but in the process I had some difficulties with getting
moonlight set up just the way I like it. So I figured these might be helpful to
others.</p>

<p>My goal is to have a PC that I use exclusively for streaming games via
<a href="https://app.lizardbyte.dev/Sunshine/?lng=en-US">sunshine</a>. Sunshine is the
replacement for Nvidia game streaming that was deprecated, and work as a
complement to the streaming client <a href="https://moonlight-stream.org/">moonlight</a>.
It allows for the streaming of video and audio to a client, which in turn
streams controls (keyboard and / or a controller) back to the server.</p>

<p>When all is said and done, I want what is effectively a box in my closet with
only two things attached: a power cable, and an ethernet cable (for a
low-latency wired connection to my network). I do not want dangling mice,
keyboards or monitors. Just a box that connects to the internet, and is
available for me to stream from.</p>

<p>To accomplish this, I needed a few things:</p>

<ol>
  <li>A way to have a virtual display even if a physical monitor isn’t plugged in.</li>
  <li>A way to login as a user right away (since sunshine needs a valid user).</li>
  <li>A way to have sunshine available when the machine boots.</li>
  <li>A way to wake the machine after it suspends</li>
</ol>

<h2 id="attaching-a-virtual-display">Attaching a virtual display</h2>

<p>This was relatively easy!</p>

<p>You can buy a <a href="https://www.google.com/search?q=dummy+plug+hdmi">dummy plug</a> that
you just plug into the GPU. When you’ve got your PC set up, just replace your
actual monitor with that.</p>

<h2 id="logging-in-right-away">Logging in right away</h2>

<p>This one just requires careful setup:</p>

<ol>
  <li>setup autologin in your operating system (varies by distro).</li>
  <li><em>do not</em> use disk encryption.</li>
</ol>

<p>(2) is the major gotcha: if you add disk encryption it’ll ask for your password
every time your computer starts up, which means plugging in a keyboard
every time. you could just leave a keyboard by your computer for this purpose,
but I’ve found I do have to restart my computer from time to time, and making
bringing it back up as easy as pressing a button is a nice usability improvement.</p>

<h2 id="start-sunshine-when-the-machine-boots">Start sunshine when the machine boots</h2>

<p>This was pretty hard for me. Normally, this is a matter of installing the
sunshine .deb from the <a href="https://github.com/LizardByte/Sunshine/releases">github
releases</a>, but in my case I had
to use Ubuntu 25.05 for a newer kernel version that supports my AMD GPU. Only
LTS release are supported for sunshine.</p>

<p>For a non-lts release, I found that using the <code class="language-plaintext highlighter-rouge">.appimage</code> worked the best. This
unfortunately didn’t work for me without root, so I had to run sunshine as sudo:</p>

<p><code class="language-plaintext highlighter-rouge">sudo -i PULSE_SERVER=unix:/run/user/$(id -u $whoami)/pulse/native /usr/bin/sunshine</code></p>

<p>(I moved the appimage to /usr/bin/sunshine).</p>

<p>I put this in a script, which I then added as a <a href="https://help.ubuntu.com/stable/ubuntu-help/startup-applications.html.en">startup application</a>:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
<span class="c"># I had to add a sleep to let the graphical interface completely come up.</span>
<span class="c"># otherwise I would see a black screen.</span>
<span class="nb">sleep </span>10
<span class="nb">exec sudo</span> <span class="nt">-i</span> <span class="nv">PULSE_SERVER</span><span class="o">=</span>unix:/run/user/<span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span> <span class="nv">$whoami</span><span class="si">)</span>/pulse/native /usr/bin/sunshine
</code></pre></div></div>

<p>This works, but still has some wonkiness:</p>

<ul>
  <li>steam can’t be launched via moonlight because it tries to start it as root.</li>
</ul>

<h2 id="a-way-to-wake-the-machine-after-it-suspends">A way to wake the machine, after it suspends</h2>

<p>Now you probably don’t want your machine on all the time - instead, you’d want
it to suspend after a reasonable idle time frame, and have the ability to turn
it one when you need it.</p>

<p>I tried a few approach, none of which worked or were reliable (I think something
else was resetting my network configuration):</p>

<ul>
  <li><a href="https://wiki.archlinux.org/title/Wake-on-LAN">adding a rule to /systemd/network</a></li>
  <li>Adding a vanilla systemd unit to run ethtool.</li>
</ul>

<p>Ultimately I landed on the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># /lib/systemd/system/wol@.service
[Unit]
Description=Wake-on-lan for %i
# This means run after the network is online, as well
# as after suspension.
After=network-online.target suspend.target

[Service]
Type=oneshot
# something else in my OP keeps setting the WOL settings on the device.
# adding this sleep gave whatever time to configure it's settings, so I could override them.
ExecStartPre=/usr/bin/sleep 10
ExecStart=/sbin/ethtool -s %i wol g

[Install]
# if we run network-online and suspend.target, run this too.
WantedBy=network-online.target suspend.target
</code></pre></div></div>

<p>Installed by:</p>

<p><code class="language-plaintext highlighter-rouge">systemctl enable wol@${ethid}</code></p>

<p>Where <code class="language-plaintext highlighter-rouge">${ethid}</code> is the interface id you can get from <code class="language-plaintext highlighter-rouge">nmcli</code>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>And that’s it! Most of it was troubleshooting systemd units. My takeaways are:</p>

<ul>
  <li>try to use systemd units as much as possible. It’s an extremely powerful
system and enables you to start your process with the right sequencing and situations.</li>
  <li>try to use LTS releases of Ubuntu if at all possible. Moonlight installation
has been tricky, and I’m sure other packages only support LTS. I’m looking
forward to upgrading to 2026.04 precisely for this benefit.</li>
</ul>

<h3 id="why-linux-why-ubuntu">Why linux? Why ubuntu?</h3>

<p>Although not for everyone, I like to use Linux for a few reasons:</p>

<ol>
  <li>Linux distributions don’t to forced updates, thereby allowing gaming
uninterrupted by some malware update.</li>
  <li>Windows has a ton of bloatware and ads.</li>
  <li>Linux is “free” - it doesn’t cost a cent to run it, and distros often work
for years.</li>
  <li>With the work done on <a href="https://www.winehq.org/">wine</a> and
<a href="https://github.com/ValveSoftware/Proton">proton</a>, Windows games run
extremely smooth on Linux now.</li>
</ol>

<p>For Ubuntu, I would go with <a href="https://bazzite.gg/">bazzite</a> for a pure gaming PC,
but as this computer will be the most powerful one I have, I wanted it to have
the option to be more general purpose in case I get the itch to do some real
software development on it (maybe ML or some CPU emulation project).</p>]]></content><author><name></name></author><category term="computers" /><summary type="html"><![CDATA[Setting up a streaming gaming Ubuntu PC for moonlight]]></summary></entry><entry><title type="html">OKRs and goal setting</title><link href="https://y.tsutsumi.io/okrs/" rel="alternate" type="text/html" title="OKRs and goal setting" /><published>2025-07-11T07:00:00+00:00</published><updated>2025-07-11T07:00:00+00:00</updated><id>https://y.tsutsumi.io/okrs-and-goal-setting</id><content type="html" xml:base="https://y.tsutsumi.io/okrs/"><![CDATA[<h1 id="okrs-and-goal-setting">OKRs and goal setting</h1>

<p>I’ve had a lot of conversations around OKRs, so I wanted to write down my
thoughts around them.</p>

<h2 id="what-are-okrs-and-how-are-they-defined">What are OKRs, and how are they defined</h2>

<p>OKRs stand for “objectives” and “key results”.</p>

<p>OKRs were developed by Andy Grove at Intel in the 1970s and later popularized by
John Doerr, who learned about them while working at Intel, and then introduced
them to Google in 1999. The framework has since been adopted by many technology
companies and organizations worldwide.</p>

<p><strong>Objectives</strong> are qualitative, inspirational goals that answer the question “What do we want to achieve?” They should be:</p>
<ul>
  <li>Clear and specific</li>
  <li>Time-bound (typically quarterly)</li>
  <li>Ambitious but achievable</li>
  <li>
    <h2 id="aligned-with-company-strategy">Aligned with company strategy</h2>
    <p>Objectives create alignment across teams and drive focus on the most important
priorities for the organization.</p>
  </li>
</ul>

<p><strong>Key Results</strong> are quantitative, measurable outcomes that answer the question “How will we know if we achieved our objective?” They should be:</p>
<ul>
  <li>Specific and measurable</li>
  <li>Time-bound</li>
  <li>Aggressive but realistic</li>
  <li>Leading indicators of success</li>
</ul>

<p>Key results provide a quantitative measure of an objective: if all of the KRs
are reached, the objective is considered accomplished.</p>

<h2 id="hierarchy-of-okrs">Hierarchy of OKRs</h2>

<pre><code class="language-mermaid">graph TD
    O[Objective: Improve Customer Satisfaction]
    KR[Key Result: Achieve 90% Customer Satisfaction Score]
    P[Project: Implement Customer Feedback System]

    P --&gt; KR --&gt; O
</code></pre>

<p>This hierarchy shows how:</p>
<ul>
  <li><strong>Objectives</strong> (top level) define what you want to achieve</li>
  <li><strong>Key Results</strong> (middle level) measure progress toward objectives</li>
  <li><strong>Projects</strong> (bottom level) are the actual work initiatives that drive key results</li>
</ul>

<h2 id="addressing-okr-concerns">Addressing OKR Concerns</h2>

<p>I’ve often heard from many ICs and technical managers that OKRs feel like a
pedantic exercise that only serves as busywork, and doesn’t provide real value
to the organization, or might constrain the scope of the work unnecessarily. I
hope to argue that, with the right process, OKRs can be neither.</p>

<h3 id="okrs-create-a-common-language-of-communication">OKRs create a common language of communication</h3>

<p>In my experience working with senior leadership teams, the biggest challenge in
communication comes from <em>not articulating engineering projects in terms of a
measure that leadership can truly appreciate</em>. This requires a mindset shift,
especially for engineers who are used to dealing with problems that require deep
context to solve and fully appreciate.</p>

<p>Senior leaders often have dozens, if not hundreds of members in their
organization. They will likely not have the bandwidth to intimately understand
the work you’re doing, although they probably want to. This puts an individual
engineer or a team at a risk: if there is a disconnect in context and a common
language across the two levels, the engineer may be working on amazing things
that go unrecognized, and the leader may miss the opportunity to give critical
feedback on the alignment of goals. OKRs serve as that missing common language,
helping frame the technical work being done in terms of the impact to the
organization and a quantitative way to measure it.</p>

<h3 id="concern-okrs-are-too-heavyweight">Concern: OKRs are too heavyweight</h3>

<p>When there is feedback that the OKR process is busywork, I think a lot of that
comes from a heavyweight OKRs process. Including:</p>

<ul>
  <li>A process that forces very stringent requirements and arguing pedantries, like
requiring specific phrasing or formatting.</li>
  <li>A process that stretches weeks at a time, where the next OKR planning begins
only a short while after the previous planning was complete.</li>
  <li>Planning that is too frequent, where a team doesn’t even have a chance to
deliver the previous OKRs.</li>
</ul>

<p>To mitigate those, I suggest:</p>

<ul>
  <li>OKR planning no more than once a quarter. Every six months would be a better
cadence, if it’s possibly to plan that far ahead.</li>
  <li>OKR planning process only last 2 weeks: this forces a lot of thinking and
collaboration, but leaves 10 weeks or more to focus on execution.</li>
</ul>

<h3 id="concern-things-change-too-quickly-to-write-good-okrs">Concern: things change too quickly to write good OKRs</h3>

<p>This is a valid criticism. OKRs are built around long-term planning, and
sometimes that isn’t always possible. If a KR is shifting constantly, it may be
a sign of, frankly, some organizational dysfunction that any goal setting
exercise cannot address.</p>

<p>However, this is also often a symptom of the OKRs themselves: perhaps the OKRs
have over-specified and implementation detail, rather than serve as a measure of
the achievement of a goal.</p>

<p>Taking improving the performance of a C++ codebase as an example. An
overspecified KR may look like:</p>

<ul>
  <li>update clangd and achieve a 20% latency reduction in web service latency.</li>
</ul>

<p>The “update clangd” detail is superfluous and overspecified: the goal is to make
things faster, and if you find some better way to do that after a couple weeks
of investigation, you should be able to switch the approach whenever to achieve
that.</p>

<h3 id="concerns-the-scope-of-the-krs-is-too-constrained">Concerns: the scope of the KRs is too constrained</h3>

<p>Sometimes a KR can feel like it’s constraining you to a specific solution. I
have found that this, similar to a KR that goes stale quickly, is often
caused by being too tightly coupled to a specific solution.</p>

<p>A solution may change mid-quarter, and the KRs should be authored so that as
long as the outcome is achieved, it can be considered complete.</p>

<h2 id="examples-of-bad-objectives">Examples of bad objectives</h2>

<ul>
  <li>not framed in terms of a business goal:
    <ul>
      <li>bad: “oncall rotation”</li>
      <li>good: “achieve high availability of P0 services”</li>
    </ul>
  </li>
</ul>

<h2 id="examples-of-bad-krs">Examples of bad KRs</h2>

<ul>
  <li>overspecified: A KR that includes precise implementation details.
    <ul>
      <li>bad: “achieve a 20% latency improvement by adding flash attention support”</li>
      <li>good” “achieve a 20% latency improvement in model training”</li>
    </ul>
  </li>
  <li>underspecified: A KR that doesn’t include a specific target.
    <ul>
      <li>bad: “ship fewer bugs”</li>
      <li>good: “20% fewer P0 issues discovered in production” or “3 or less P0 incidents in production”</li>
    </ul>
  </li>
  <li>unmeasurable: A KR that is not quantifiable.
    <ul>
      <li>bad: “users are happy with their CI execution”</li>
      <li>good: “p99 for CI test execution is within 2 minutes”</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="okrs" /><summary type="html"><![CDATA[OKRs and goal setting]]></summary></entry><entry><title type="html">Finding a low latency game controller</title><link href="https://y.tsutsumi.io/low-latency-gaming-controller/" rel="alternate" type="text/html" title="Finding a low latency game controller" /><published>2025-06-27T07:00:00+00:00</published><updated>2025-06-27T07:00:00+00:00</updated><id>https://y.tsutsumi.io/low-latency-controllers</id><content type="html" xml:base="https://y.tsutsumi.io/low-latency-gaming-controller/"><![CDATA[<h1 id="finding-a-low-latency-game-controller">Finding a low latency game controller</h1>

<p>I’ve been playing some <a href="https://www.expedition33.com/">Clair Obscur: Expedition
33</a>, and it’s an amazing game.</p>

<p>However, one of the major issues I run into is with timing the dodges: during
battles on the hardest difficulty, if you don’t dodge, your party dies very quickly:</p>

<p><img src="2025-06-27-low-latency-controller-exp33.png" alt="image" /></p>

<p>Dodging comes down to timing pressing a button right when the enemy attacks.
It isn’t easy, but I noticed that I was having a really hard
time with it. That’s when I realized that it was due to my controller (the <a href="https://www.8bitdo.com/lite2/">8bitdo Lite 2</a>).</p>

<h2 id="what-affects-controller-latency">What affects controller latency?</h2>

<p>There are two main factors to consider:</p>

<ul>
  <li>The <em>polling rate</em> of the controller: how frequently it checks to see if a
button or stick is pressed. This can introduce a maximum delay of <code class="language-plaintext highlighter-rouge">1000ms /
freq_hz</code>.</li>
  <li>The <em>connection latency</em> of the controller: the amount of time it takes for a
signal to reach the device. For bluetooth this can be highly variable, while
wired and 2.4Ghz connections can be much more stable.</li>
</ul>

<p>In my case, there is a third factor, since I’m streaming my setup via
<a href="https://moonlight-stream.org/">moonlight</a>: the latency between my device and
the device running the game. On a 5Ghz wireless connection in my house, that’s
3-4 milliseconds.</p>

<h2 id="8bitdo2-lite-2-latency">8bitdo2 Lite 2 latency</h2>

<p>So what was the worst-case latency of the 8bitdo Lite 2? We can reference <a href="https://www.youtube.com/watch?v=O6cZIfD6uLw">this
youtube review</a>, which has an
excellent test.</p>

<p>The bottom line looks like:</p>

<ul>
  <li>Average polling rate 44hz, so 22 milliseconds!</li>
</ul>

<p>The review didn’t mention bluetooth, so I’m looking for a way to test that. But
assuming at least an additional 4-5 milliseconds of latency, that’s 25
milliseconds it’s adding to those button presses!</p>

<h2 id="what-is-the-best-low-latency-controller">What is the best low latency controller?</h2>

<p>In short, look at <a href="https://gamepadla.com/">gamepedla</a>, which has timings for
many controllers.</p>

<p>But I chose the <a href="https://www.8bitdo.com/ultimate-2-wireless-controller/">8bitdo Ultimate
2</a>. At a 1000hz polling
rate and measured sub 5ms latency for both wired and via 2.4Ghz, It’ll ensure a
lag-free experience if needed. In addition, the 10ms bluetooth latency isn’t too
bad!</p>

<p>While I’m waiting for that, I had an Xbox Core Controller lying around, and the
latency there <a href="https://gamepadla.com/xbox-core-controller.html">isn’t bad at
all</a>. Even on bluetooth it’s
11-12ms, comparable to bluetooth on the 8bitdo Ultimate 2.</p>]]></content><author><name></name></author><category term="gaming" /><summary type="html"><![CDATA[Finding a low latency game controller]]></summary></entry><entry><title type="html">My tips on debugging</title><link href="https://y.tsutsumi.io/debugging" rel="alternate" type="text/html" title="My tips on debugging" /><published>2025-06-07T07:00:00+00:00</published><updated>2025-06-07T07:00:00+00:00</updated><id>https://y.tsutsumi.io/debugging</id><content type="html" xml:base="https://y.tsutsumi.io/debugging"><![CDATA[<h1 id="my-tips-on-debugging">My tips on debugging</h1>

<p>Updated: 2025-06-07</p>

<p>This is a running collection of my thoughts on debugging. I’ll update these over time.</p>

<h2 id="improve-errors-minimize-print-statements">Improve errors, minimize print statements</h2>

<p>One common type of debugging is “print” style - just print the data you need at the time. Often this occurs because you don’t have enough information in the error itself:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"conflicting args"</span><span class="p">)</span>
</code></pre></div></div>

<p>Rather than add a print statement temporarily, just make the error better - it helps the next person when they come along:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s">"conflict args. Args found: </span><span class="si">{</span><span class="n">args</span><span class="si">}</span><span class="s">)
</span></code></pre></div></div>]]></content><author><name></name></author><category term="coding" /><summary type="html"><![CDATA[My tips on debugging]]></summary></entry><entry><title type="html">Result, Situation, Action: a new take on the STAR format</title><link href="https://y.tsutsumi.io/rsa" rel="alternate" type="text/html" title="Result, Situation, Action: a new take on the STAR format" /><published>2025-02-08T07:00:00+00:00</published><updated>2025-02-08T07:00:00+00:00</updated><id>https://y.tsutsumi.io/result-situation-action</id><content type="html" xml:base="https://y.tsutsumi.io/rsa"><![CDATA[<h1 id="result-situation-action">Result, Situation, Action</h1>

<p>The <a href="https://en.wikipedia.org/wiki/Situation,_task,_action,_result">STAR</a> format
of answering an interview question is very popular. But in my experience a twist
on that ends up being more effective: result, situation, then action.</p>

<p>The STAR format kind of buries the lead - it forces the interviewer into a
long-winded story and they’re not engaged because they don’t understand the
value of it. By giving them some idea of the impact that your story had (e.g. I
saved the company $XXX dollars, we reduced developer wait times by 20 minutes on
a 1-hour task), that gives the interviewer a reason to listen.</p>

<p>In addition, I find the “task” part of the story tends to be extraneous - when
you only have 30 minutes to an hour with the interviewer <em>total</em>, you need to
shave the minutes where it matters.</p>

<p>Although the whole “my task was X” may take 1 minute to explain, it’s better to just explain what you <em>did</em>.</p>

<h2 id="example">Example</h2>

<p>Result: I increased revenue for the company by XX percent.</p>

<p>Situation: In multiple customer meetings, I noticed that in the follow-up of
customers meetings, they would always mention having trouble onboarding onto
feature X.</p>

<p>Action: I wrote up a user guide, and we added a link the first time a customer
accessed the feature, as well as included it in the onboarding guide.</p>

<h2 id="summary">Summary</h2>

<p>I call this “RSA” pronounced “rizza”. Try it out!</p>]]></content><author><name></name></author><category term="coding" /><summary type="html"><![CDATA[Result, Situation, Action]]></summary></entry><entry><title type="html">Many and granular: ideal code organization in Bazel repos</title><link href="https://y.tsutsumi.io/bazel-many-and-granular" rel="alternate" type="text/html" title="Many and granular: ideal code organization in Bazel repos" /><published>2025-01-29T07:00:00+00:00</published><updated>2025-01-29T07:00:00+00:00</updated><id>https://y.tsutsumi.io/bazel-many-and-granular</id><content type="html" xml:base="https://y.tsutsumi.io/bazel-many-and-granular"><![CDATA[<h1 id="better-code-organization-in-bazel">Better code organization in bazel</h1>

<p>As part of my work on <a href="https://y.tsutsumi.io/depsaw/">depsaw</a>, I did a lot of
investigation into scenarios where we were overbuilding, and the solution for
those. Here’s some thoughts on code organization based on that exploration.</p>

<h2 id="more-granular-packages-are-better-than-fewer-packages">More granular packages are better than fewer packages</h2>

<p>The original post has <a href="https://y.tsutsumi.io/depsaw/#2-causes-and-solutions">a few scenarios
enumerated</a> of why
something is overbuilding, but I’ll repeat them here:</p>

<ol>
  <li>Too many files in a single package: this causes the package to change more
  frequently, but the dependant only needs a couple of the files.</li>
  <li>Too much functionality in a single file: there might be a file with thousands
  of lines of code, but only one function is relevant to a dependent.</li>
  <li>Unnecessary dependencies. Where a target has a dependency it doesn’t use at
all.</li>
</ol>

<p>Zooming in one (1) and (2) for a second: I think this points to a more
fundamental law about code organization in bazel: that packages should be “many
and granular”. Aside from just an incorrect declaration, the other solution to
overbuilding is basically “split the package”. Implying that if the dependencies
were granular to begin with, we would have preemptively solved overbuilding.</p>

<p>This is also outlined in the bazel <a href="https://bazel.build/configure/best-practices">best
practices</a>:</p>

<blockquote>
  <p>To use fine-grained dependencies to allow parallelism and incrementality.</p>
</blockquote>

<h2 id="a-shallow-hierarchy-is-better-than-a-deeper-one">A shallow hierarchy is better than a deeper one</h2>

<p>Although tied to the above, but still worth explicitly stating: a shallow
hierarchy is better than a deep one. For example,</p>

<pre><code class="language-mermaid">graph LR
    C --&gt; A
    C --&gt; B
    D --&gt; A
    D --&gt; B
    E --&gt; A
    F --&gt; B
</code></pre>

<p>Is better than:</p>

<pre><code class="language-mermaid">graph LR
    B --&gt; A
    C --&gt; A
    D --&gt; B
    E --&gt; B
    F --&gt; B
</code></pre>

<p>A shallow hierarchy:</p>

<ul>
  <li>Helps prevent pulling in functionality from upstream dependencies (better
depend-on-what-you-use).</li>
  <li>Makes it easier to sever and refactor dependencies (fewer layers to have to
navigate through).</li>
</ul>

<h2 id="summary">Summary</h2>

<ul>
  <li>more packages are better than fewer packages.</li>
  <li>granular, composable functionality is better than giant functionality.</li>
  <li>a shallow hierarchy of dependencies is better than a deeper one.</li>
</ul>]]></content><author><name></name></author><category term="coding" /><summary type="html"><![CDATA[Better code organization in bazel]]></summary></entry><entry><title type="html">Reflecting on 2024</title><link href="https://y.tsutsumi.io/my-year/2024" rel="alternate" type="text/html" title="Reflecting on 2024" /><published>2025-01-03T07:00:00+00:00</published><updated>2025-01-03T07:00:00+00:00</updated><id>https://y.tsutsumi.io/my-year/reflecting-on-2024</id><content type="html" xml:base="https://y.tsutsumi.io/my-year/2024"><![CDATA[<p>I’m reflecting on my personal time during 2024. A lot of my time was spent
working on things with my family that I won’t share here, but nontheless I did
make some progress with my personal goals.</p>

<h2 id="farsi">Farsi</h2>

<p>This year, I think my Farsi has gotten quite a bit better:</p>

<ul>
  <li>Conversationally I can express most things.</li>
  <li>I can watch some Farsi TV and news and get the general idea.</li>
</ul>

<p>The only video game with a Farsi translation I found is <a href="https://childrenofmorta.com/">Children of
Morta</a>: I guess one of the developers is Iranian
and wanted to get a Farsi translation in. I’m super thankful for that, so I can watch those cutscenes a few times and learn the Farsi from there.</p>

<p>The big thing I did is start listening to TV in the car regularly: it’s a good
way to reinforce my listening abilities.</p>

<p>I still take Farsi lessons weekly. For 2025, I think I’ll continue at this pace,
and loosely target being able to listen and understand Farsi TV.</p>

<h2 id="fitness-and-health">Fitness and Health</h2>

<p>I’ve continued working on fitness this year. Primarily lowering body fat,
building muscle, and lowering my apob.</p>

<p>I haven’t taken a Dexa scan since July, but my body fat actually went up at the
time compared to January: I think it was due to a two-week long trip I took to
Japan in June. I was not able to work out at all, and also walked a significant
amount of time so I was still, somewhat, in a caloric deficit.</p>

<p>That said, my weight at the end of the year is about 174 pounds. Losing roughly
4 pounds in the first half of the year to 176, and 2 pounds in the last half.
I’m not sure where my body fat is at, but likely 13% where it stood in July.</p>

<p>Interestingly I lost muscle mass across the board except for my stomach in July.
I still need to check to see if I was able to regain it or not.</p>

<p>I’ve found a good routine for a caloric deficit and overall weight loss, which
is:</p>

<ul>
  <li>400 calories daily burned at the treadmill (walking 30 minutes at 3.5mph, at a
12 degree incline).</li>
  <li>A 30 minute weightlifting workout, mixing in some crossfit-style workouts from
time to time to do some interval training.</li>
  <li>Maintaining ~1400 calories a day.</li>
</ul>

<p>I cheat on the calories regularly, so my weight is yo-yoing for now, but I’m
able to keep it between 171 and 175, and able to lose a pound a week with the
above. Given the holidays, I think this is invitable, but hoping to get back on
the wagon next year.</p>

<p>I upped my protein to 1.6g protein / kg, which I’ve read is about where the
benefits to hypertrophy level off.</p>

<p>For 2025, with a consistent technique to lose weight, I’m shifting my focus to
figure out how to build more muscle. I think there’s a lot of optimization I’m
missing out on there.</p>

<h2 id="japanese">Japanese</h2>

<p>For this year, my Japanese took a back burner. I stopped taking regular Japanese
lessons. Honestly I think to maximize those lessons, I would have to start doing
some pretty complex assignments like writing of papers and whatnot. It’s not
something I’m that interested in investing time into.</p>

<p>For now, I’ll just play video games in Japanese when I can. I have Witcher 3 and
the Tactics Ogre remake, which will be dozens of hours and are already
challenging me with new vocabulary.</p>

<h2 id="oss-aepdev">OSS: aep.dev</h2>

<p>aep.dev made a ton of progress! Don’t just take my word for it -  check out our
<a href="https://aep.dev/blog/2024-in-review/">public blog post</a> on the topic.</p>

<p>I’m very proud of the fact that we finally moved from just theoretical benefits
to the client tooling, to real UIs and clients. If you author an AEP-compliant
specification, you can get a <a href="https://github.com/aep-dev/aepcli">command line for
free</a>. We’re working on a web
<a href="https://github.com/aep-dev/aep-explorer">UI</a>, and have some prototyping of a
Terraform/OpenTofu provider as well.</p>

<p>With the progress we’ve made this year, I’m very excited about using that as a
foundation for continued progress in aep.dev in 2025. This could be the year we
really build out a full offering, and provide something compelling to adopters
of our API specification!</p>

<h2 id="goals-for-2025">Goals for 2025</h2>

<p>For 2025, my goals are still to primarily have ample time to do impromptu things
with my family. But I do have a few goals:</p>

<ul>
  <li>Get a roadmap for aep.dev</li>
  <li>Play piano 10 minutes a day. Last year, I did not learn new 5 piano pieces.
Darn! But I’ll make this my new goal for the year. My goal this year is to be
able to play piano pieces from just reading sheet music.</li>
  <li>Be able to understand persian news.</li>
  <li>Achieve 11% body fat, without losing muscle mass.</li>
</ul>]]></content><author><name></name></author><category term="2024" /><category term="reflection" /><summary type="html"><![CDATA[I’m reflecting on my personal time during 2024. A lot of my time was spent working on things with my family that I won’t share here, but nontheless I did make some progress with my personal goals.]]></summary></entry><entry><title type="html">Winning Deduckto</title><link href="https://y.tsutsumi.io/deduckto/" rel="alternate" type="text/html" title="Winning Deduckto" /><published>2024-12-31T07:00:00+00:00</published><updated>2024-12-31T07:00:00+00:00</updated><id>https://y.tsutsumi.io/deduckto</id><content type="html" xml:base="https://y.tsutsumi.io/deduckto/"><![CDATA[<h1 id="winning-deduckto">Winning Deduckto</h1>

<p>For the holidays, my kids got a game called
<a href="https://gamewright.com/product/deduckto">Deduckto</a>. It’s a cute game for 8
years and older, where each player has their own mystery suspect which consists
of a suspect (like a pig), a disguise (a mustache), and a location (the
library). The goal of the game is to be able to identify all three attributes.</p>

<p>The game works by playing cards that are also a suspect, disguise, and location,
and putting each one into piles of “yes”, where there is one or more attributes
shared by a card, or “no” where none of the attributes are shared.</p>

<p>The game is meant for children and building their reasoning ability. And for my
kids, it’s been a great way for them to exercise that skill. I usually play more
cooperatively, where I talk with my kids about what the possibilities are, and
help them find relationships they didn’t before, like the fact that a card in
the “no” pile eliminates all of the attributes as possibilities.</p>

<p>So optimal play, I’m sure, won’t be the goal for most. That said: what is the
most optimal way to play? Here’s my thoughts.</p>

<h2 id="tldr">TLDR</h2>

<p>Try to get as many pairs of cards that have a single common attribute in the
“yes” pile as possible. The strategy is:</p>

<ol>
  <li>If possible, play a card with only one common attribute with a single “yes”
card you already have.</li>
  <li>If you have no such card, play a card that shares nothing in common with any
of your yes or no cards, to find a new “yes” card. Between the two, prefer
yes (since something that matches cards you already have), then no.</li>
</ol>

<h2 id="why">Why</h2>

<p>The optimal play is the one that eliminates the most possibilities.</p>

<p>Getting a “no” will at most eliminate three possiblities: a suspect, a disguise,
and a location.</p>

<p>Getting a “yes” can, at best, validate three attributes. But in most cases, it
will validate one. One way that is done by finding a pair of cards that are
disjoint in all but one attribute, but both are yes.</p>

<p>If you find a common attribute, you immediately eliminate all the other choices
for that feature. That means you can eliminate up to 6 other possibilities in a
single turn! Much more effective than eliminate 6 possibilities with 6 cards.</p>

<p>Getting a pair of yes cards would leave one of two possibilities:</p>

<ol>
  <li>The common attribute matches the secret suspect (e.g. they both are at the
“library”).</li>
  <li>The two cards match for a different reason, and each on a separate attribute
(e.g. for a (fox,bandana,library) and a (bear,mustache,library), fox and
mustache are matching or  bear and bandana are matching).</li>
</ol>

<p>Either could be validated by having a <em>third</em> matching card that shares
attributes with one or the other. And so on.</p>

<p>Among the cards, you will have the following, in order of preference to play.</p>

<ol>
  <li>card(s) that share 2 attributes, each with one or more yes cards, if the
attributes are not yet validated.</li>
  <li>card(s) that share 1 attribute with only one yes card, that does not already
share an attribute with another yes card.</li>
  <li>card(s) that share 1 attribute with two other yes cards.</li>
  <li>card(s) that share 0 attributes with any yes cards.</li>
  <li>all other cards.</li>
</ol>

<p>The reason is:</p>

<p>1: This will validate multiple attributes simultaneously. Although rare, it is
an ideal play.</p>

<p>2: A single attribute, common with a single yes card, will help identify a
unique attribute of your suspect.</p>

<p>3: This will help confirm that the attribute shared by the other 2 cards is
indeed the card that is unique to the suspect.</p>

<p>3: The above work to validate attributes your suspect may have. But if you can’t
do that, then it’s best to find new “yes” cards. The best way to do that is to
play unique cards as much as possible, disjoint to “yes”es, but ideally also
“no”s as well.</p>

<p>Anything else is effectively useless, giving no information.</p>]]></content><author><name></name></author><category term="board-games" /><summary type="html"><![CDATA[Winning Deduckto]]></summary></entry><entry><title type="html">depsaw: analyze and stop overbuilding in bazel</title><link href="https://y.tsutsumi.io/depsaw/" rel="alternate" type="text/html" title="depsaw: analyze and stop overbuilding in bazel" /><published>2024-12-27T07:00:00+00:00</published><updated>2024-12-27T07:00:00+00:00</updated><id>https://y.tsutsumi.io/depsaw</id><content type="html" xml:base="https://y.tsutsumi.io/depsaw/"><![CDATA[<h2 id="summary">Summary</h2>

<p>Today, I’m introducing <a href="https://github.com/toumorokoshi/depsaw/">depsaw</a>: an
experimental tool that can be used to reduce overbuilding and overtesting in bazel.</p>

<p>In its current state, it is a tool that is used to analyze the dependency graph
and commit frequencies per file to produce a list of targets that could be
optimized significantly.</p>

<p>Here is an example from the <a href="https://github.com/bazelbuild/bazel">bazel</a> codebase itself:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>depsaw trigger-scores-map ~/workspace/bazel <span class="s2">"//:bazel-distfile"</span>
targets:
- name: //src/main/java/com/google/devtools/build/lib/analysis:srcs
  rebuilds: 3604
  immediate_dependents: 1
  total_dependents: 5
  score: 3604
- name: //src/test/shell:srcs
  rebuilds: 3092
  immediate_dependents: 1
  total_dependents: 4
  score: 3092
- name: //src/main/java/com/google/devtools/build/lib/bazel:srcs
  rebuilds: 2741
  immediate_dependents: 1
  total_dependents: 5
  score: 2741
- name: //src/test/java/com/google/devtools/build/lib/rules:srcs
  rebuilds: 2647
  immediate_dependents: 1
  total_dependents: 5
  score: 2647
... <span class="c"># a few thousand other lines</span>
</code></pre></div></div>

<p>This shows that <code class="language-plaintext highlighter-rouge">//src/main/java/com/google/devtools/build/lib/analysis:srcs</code>
caused 3604 rebuilds of <code class="language-plaintext highlighter-rouge">//:bazel-distfile</code> and its dependents over the history
of the repo.</p>

<p>In the future, I’d like to also introduce tooling to help automatically reduce
or split dependencies. If you want to just dive in, look at the
<a href="https://github.com/toumorokoshi/depsaw/tree/main?tab=readme-ov-file#depsaw">readme</a>
and give it a shot! If you’re interested in learning the story and design
considerations, read on.</p>

<h2 id="backstory-overbuilding-and-overtesting-downstream-targets">Backstory: overbuilding and overtesting downstream targets</h2>

<p>At Cruise, we use <a href="https://bazel.build">bazel</a> as our build system for a
significant chunk of the code base. Combined with a monorepo (where all source
code for an organization is in a single code repository), it has allowed for a
fluid experience with building and testing software. This will not be a deep
dive into bazel and its capabilities, but bazel at a high level organizes
projects in the following way:</p>

<ol>
  <li>Source <em>files</em> are consumed into buildable units known as <em>targets</em>. Each
target is generated from a <em><a href="https://bazel.build/extending/rules">rule</a></em>.</li>
  <li>Targets can be dependants for other targets, runnable as
tests, or as a generic executable (e.g. a command-line interface).</li>
  <li>Bazel runs in two phases: an analyze phase that is able to understand the
relationship between these dependencies.</li>
</ol>

<p>Bazel has rules and <a href="https://bazel.build/extending/toolchains">toolchains</a> for a
wide variety of languages, allowing intermingling of python on C/C++
dependencies (e.g. with pybind), or adding in a static file (e.g. yaml or some
binary asset) that a target depends upon.</p>

<p>Like all codebases, functionality gravitates toward a few upstream dependencies,
on which thousands or more downstream targets depend on. For example, a utility
library for wrapping shell scripts might have hundreds of thousands of
dependants.</p>

<p>To reduce the cost of building everything, all the time, build systems often
cache their results. Bazel is no exception, providing both local and <a href="https://bazel.build/remote/caching">remote
caching</a> functionality. This means that you
only rebuild a target when it, or its dependencies, actually changes.</p>

<p>As this continues, we can run into <em>overbuilding</em>, where downstream targets are
rebuliding too often, even when the code they actually depend on don’t change.
This happens due to:</p>

<ol>
  <li>Depending on only a handful of files in a target that has a large number of
files in its source files.</li>
  <li>Depending on a target which pulls in another dependency, which is not used in
your particular code path or is included erreously.</li>
</ol>

<p>So how do you solve overbuilding? That’s what this post and depsaw are all
about.</p>

<h2 id="fixing-overbuilding-and-overtesting">Fixing overbuilding and overtesting</h2>

<p>If you have a codebase where things are being overbuilt, the general workflow is
to solve that is along the lines of:</p>

<ol>
  <li>Find the targets that are causing the most rebuilds: it’s good to scope the
problem to the high-value targets.</li>
  <li>Identify why the target is contributing so much to the builds. Apply the
appropriate solution.</li>
  <li>Back to 1.</li>
</ol>

<p>Let’s dive into each of those in detail.</p>

<h3 id="1-find-the-targets-causing-the-most-rebuilds">1: Find the targets causing the most rebuilds</h3>

<p>The targets that are causing rebuilds comes down to a couple dimensions:</p>

<ol>
  <li>Invalidations of the target’s builds. Targets can invalidate frequently
because:
    <ul>
      <li>They depend on a things that also invalidate frequently.</li>
      <li>There are a frequent changes to their source files.</li>
    </ul>
  </li>
  <li>Dependants. If you have a target that hundreds or thousands of other targets
depend on, that can cascade and result in invalidating downstream targets
very frequently.</li>
</ol>

<p>We can create a scoring like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>score(target) = total_recursive_dependants(target) * len(commits_to_build(target))
</code></pre></div></div>

<p>The score is very high if there are a lot of dependents, or the target itself is
changing very frequently. This is actually very similar to the <a href="https://www.youtube.com/watch?v=k4H20WxhbsA&amp;t=534s">metrics that
Spotify used to analyze their overbuilding for their mobile
apps</a>.</p>

<p>Here’s a table to help you get a sense of the score:</p>

<table>
  <thead>
    <tr>
      <th>score</th>
      <th>dependents</th>
      <th>average_distinct_commits_per_file</th>
      <th>num_input_files</th>
      <th>commits_dependencies_built</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1000</td>
      <td>100</td>
      <td>1</td>
      <td>10</td>
      <td>0</td>
    </tr>
    <tr>
      <td>501</td>
      <td>10</td>
      <td>1</td>
      <td>1</td>
      <td>50</td>
    </tr>
    <tr>
      <td>500</td>
      <td>10</td>
      <td>10</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <td>200</td>
      <td>2</td>
      <td>1</td>
      <td>100</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>Targets that have a lot of dependents will score higher, since the invalidate
multiple targets.</li>
  <li>Targets that have a lot of rapidly input files will score higher.</li>
  <li>Targets that have a fair number of dependents, and depend on a fair number of
targets, will score higher.</li>
  <li>Targets that have a fair number of dependents, as well as have a high number
of files modified, will score higher.</li>
</ul>

<p>Using depsaw, you can get these scores with the following, running it against a
git repository using bazel:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">TARGET</span><span class="o">=</span>YOUR_TARGET_HERE
depsaw trigger-scores-map <span class="si">$(</span><span class="nb">pwd</span><span class="si">)</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TARGET</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--format</span><span class="o">=</span>csv <span class="nt">--since</span> 2024-11-01 <span class="nt">--deps-file</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DEPS_FILE</span><span class="k">}</span><span class="s2">"</span> <span class="o">&gt;</span> /tmp/deps.csv
</code></pre></div></div>

<p>Here’s some rough pseudocode of the algorithm:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">commits_to_build</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
   <span class="n">commits</span> <span class="o">=</span> <span class="n">commits_that_modified_files</span><span class="p">(</span><span class="n">targets</span><span class="p">.</span><span class="n">input_files</span><span class="p">)</span>
   <span class="k">for</span> <span class="n">dep</span> <span class="ow">in</span> <span class="n">target</span><span class="p">.</span><span class="n">dependencies</span><span class="p">:</span>
      <span class="n">commits</span> <span class="o">=</span> <span class="n">commits</span> <span class="o">|</span> <span class="n">commits_to_build</span><span class="p">(</span><span class="n">dep</span><span class="p">)</span>
   <span class="k">return</span> <span class="n">commits</span>
</code></pre></div></div>

<p>Basically, looking at all the commits that modified the input files of your
target, and taking the union of that and all the commits that would have
triggered a build of a dependency.</p>

<p>This is also recursive - which means that as you build the list of commits for
one target, you can easily build it for all the targets it depends on at the
same time.</p>

<p>We can build this algorithm by first getting the list of modified files in git,
per commit, via a command like:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="nt">--numstat</span> | <span class="nb">awk</span> <span class="s1">'/^[0-9-]+/{ print $NF}'</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
</code></pre></div></div>

<p>And use the information around dependencies extracted from bazel:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bazel query <span class="s2">"deps(//...)"</span> <span class="nt">--output</span> streamed_jsonproto<span class="sb">`</span>
</code></pre></div></div>

<h3 id="2-causes-and-solutions">2: Causes and solutions</h3>

<p>Fundamentally, overbuilding comes from depending on targets that are too big,
for one reason or another.</p>

<h4 id="too-many-files-in-a-single-package">too many files in a single package</h4>

<p>In this case, there are too many files that are grouped in the same target, such
that targets must now depend on that single mega-target, rebuilding all
dependants.</p>

<p>Solution: files should be split up into more granular targets. Using a code
search tool to find the references to various files and imports. Analyzing those
would help you determine which refactors are easiest by hand.</p>

<h4 id="too-much-functionality-in-a-single-file">too much functionality in a single file</h4>

<p>In this case, there is a single file that is depended on by too many targets.</p>

<p>Solution: separate the file into multiple other files, then split those up into
separate targets. Modify dependents to use the split dependency. Using a code
analysis tool, you can see which functions are used the most, then factor those
into separate targets.</p>

<h4 id="unnescessary-dependencies">unnescessary dependencies</h4>

<p>In this case, there are dependencies that are completely unnescessary.
Anecdotally I think this is overexagerrated as an issue, but it is possible
without some proper pruning that a target that was previously relevant no longer
is.</p>

<p>Solution: remove that target.</p>

<h2 id="conclusions-and-other-thoughts">conclusions and other thoughts</h2>

<p>This tooling has already been helpful: I’ve found opportunities to factor
dependencies of some of my targets by 30%!</p>

<p>The above process is a start, but, like depsaw, there’s a lot more to do to make
eliminating overbuilding a more automated and simpler exercise. I will probably
have a follow-up post at some point when I have some better insights. If you
have some ideas, please join the conversation at the bottom or contact me!</p>

<p>In the meantime, here’s some other musings:</p>

<h3 id="considering-sibling-dependencies-for-more-score-accuracy">Considering sibling dependencies for more score accuracy</h3>

<p>Even the score above is a bit naive - it ignores the fact that there are common
dependencies that would be pulled in via other means anyway. for example, a
utility library may be pulled in even if a different dependent is removed:</p>

<pre><code class="language-mermaid">graph LR
    A[A]
    B[B]
    C[C]
    D[D]

    A --&gt; B
    A --&gt; C
    B --&gt; D
    B --&gt; E
    C --&gt; D
</code></pre>

<p>In this case, removing B from A wouldn’t actually prevent rebuilds of Target A
when D changes, since it would still be pulled in through B and C. So the value
in removing a dependency would be more accurate if it included a way to measure
the reduction in builds by removing B, and thereby removing the dependencies
that are unique to it (like E).</p>

<p>For now, this can be emulated in depsaw by first re-running depsaw before and
after removing a dependency - this will tell you what the actual net difference
would be in eliminating that specific dependent from the graph.</p>

<h2 id="bazel-is-amazing">Bazel is amazing</h2>

<p>Although separate from the point of this post, bazel is an extremely powerful
tool. I would argue that for a monorepo to succeed, you need <em>some</em> sort of
system that is used to define the complex relationship between software units,
and is able to give you descriptive answers about these relationships. To that
end, bazel provides the <a href="https://bazel.build/query/guide">query</a> command. You
can use it to answer the following questions, and more:</p>

<table>
  <thead>
    <tr>
      <th>question</th>
      <th>bazel query</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>What targets does my code depend on?</td>
      <td><code class="language-plaintext highlighter-rouge">bazel query "deps(//foo)"</code></td>
    </tr>
    <tr>
      <td>What targets depend on the code I’m working on?</td>
      <td><code class="language-plaintext highlighter-rouge">bazel query --infer_universe_scope "rdeps(//..., //foo)"</code></td>
    </tr>
    <tr>
      <td>Why does foo depend on bar?</td>
      <td><code class="language-plaintext highlighter-rouge">bazel query "somepath(//foo, //bar)"</code></td>
    </tr>
    <tr>
      <td>What are the test targets that depend on me?</td>
      <td><code class="language-plaintext highlighter-rouge">bazel query "tests(//...) intersect rdeps(//..., //foo)"</code></td>
    </tr>
  </tbody>
</table>

<p>These types of queries are critical to identifying common build problems, including:</p>

<ul>
  <li>overbuilding: rebuilding targets that are not needed.</li>
  <li>overtesting: testing downstreams that are not actually affected by your change.</li>
  <li>identifying how an extraneous target is pulled into your dependencies.</li>
</ul>]]></content><author><name></name></author><category term="coding" /><category term="bazel" /><summary type="html"><![CDATA[Summary]]></summary></entry><entry><title type="html">Design patterns for multi-organization project management</title><link href="https://y.tsutsumi.io/multi-org-project-planning/" rel="alternate" type="text/html" title="Design patterns for multi-organization project management" /><published>2024-12-12T07:00:00+00:00</published><updated>2024-12-12T07:00:00+00:00</updated><id>https://y.tsutsumi.io/multi-org-project-planning</id><content type="html" xml:base="https://y.tsutsumi.io/multi-org-project-planning/"><![CDATA[<h1 id="design-patterns-for-organizing-multi-organization-projects">Design patterns for organizing multi-organization Projects</h1>

<p>Recently, I needed to help plan a project that spanned across dozens of teams,
as wel as product areas and VPs. My task was planning my team’s deliverables,
but to do so, there were multiple pieces of information that one had to consider,
including:</p>

<ul>
  <li>Estimates on the work my team would perform.</li>
  <li>Timelines of our dependencies, and the dependencies of my team’s dependencies.</li>
  <li>Relationships between these dependencies.</li>
  <li>Stack ranking based on business impact.</li>
</ul>

<p>The process was quite taxing, resulting in quarterly planning where we had to
dig up all the context from previous quarters, find outdated docs, and go
through a multi-day effort to get this information presentable to the senior
leadership team.</p>

<p>From that, I’ve been working on some patterns and processes, built on our
existing project management tooling, make it easier to produce these roadmaps
and extract information.</p>

<h2 id="these-patterns-work-in-most-issue-trackers">These patterns work in most issue trackers</h2>

<p>I left this blog post conceptual intentionally: it’s because these are <em>design
patterns</em>: ideas that can, for the most part, be applied to any issue tracking
tool (Jira, Smartsheet, an in-house tracker).</p>

<p>Although a custom tracker may be written for this purpose, I think that these
ideas are actually more useful as design patterns. Organizations almost always
have decided on their project tracker of choice, and it’s impractical, if not
infeasible, to replace that with a bespoke solution.</p>

<p>It’s much simpler to layer these patterns on top of existing trackers, allowing
this project structure to leverage the knowledge in the issue tracker, rather
than duplicating it.</p>

<h2 id="the-patterns">The Patterns</h2>

<h3 id="a-structured-graph-of-tasks">A structured graph of tasks</h3>

<p>I’ve seen attempts to manage large project planning in long-form documents, but
once execution has begun, the individual projects and dependencies themselves
are best off in a data structure: in particular, it should be possible to
represent the tasks themselves as nodes in an acyclic graph.</p>

<p>This type of structure allows for multiple use cases, including:</p>

<ul>
  <li>Attaching common metadata to each node (like acceptance criteria, business impact).</li>
  <li>Extracting the delivery date of a node based on the delivery dates of parent
nodes, and including the effort estimate of the current one.</li>
  <li>Visualization (e.g. gantt or graph style), helping one see what the real
dependencies are.</li>
  <li>Traversing the graph to find issues that apply to a particular category (team,
org, product area)</li>
</ul>

<h3 id="tagging-over-hierarchical-structure">Tagging over hierarchical structure</h3>

<p>Although it’s common to enforce a hierarchical structure on data (e.g. issues by
team), I think tagging (e.g. Jira labels) ends up being a more useful approach.</p>

<p>Especially with tasks, there are so many different consumers that choosing a
single structure certainly will not work for all of them. Consider:</p>

<ul>
  <li>The individual contributor who just wants to look at their issues, and maybe
their teams.</li>
  <li>The manager who wants to look at all projects for their team.</li>
  <li>The director, who wants to look at projects for their team, and possibly
others that they depend on.</li>
  <li>The project manager, who wants to see all tasks that pertain to their project,
regardless of the individual or team executing that task.</li>
</ul>

<p>This, combined with products moving teams and teams moving organizations,
creates change that makes organizational hierarchy at minimum a brittle choice.</p>

<p>With tagging, along with a convention around those, it should be very easy to
create new roadmaps (just add a new tag to all relevant issues), add one-off
issues to a view for the team or organization.</p>

<h3 id="spreadsheets-for-easy-editing">Spreadsheets for easy editing</h3>

<p>At Google, we had a giant table for bugs (likely implemented as multiple tables with foreign keys for custom fields) called buganizer. You can see a glimpse of what it looks like at https://issuetracker.google.com/issues.</p>

<p>A developer wrote a tool that would do a bidirectional sync to a Google sheet,
thereby allowing us to:</p>

<ol>
  <li>Easily review the data and fields in a data dense format.</li>
  <li>Visualize roadmaps</li>
  <li>Copy-paste the spreadsheet content into documents or presentations with
leadership.</li>
  <li>Modify the fields quickly for project planning.</li>
  <li>Add new issues as we found dependencies or tasks missing.</li>
</ol>

<p>This tool was absolutely amazing - it overcame the friction of mass
modification and at-a-glance visualization.</p>

<h3 id="metadata-to-attach-a-node">Metadata to attach a node</h3>

<p>This is not a design pattern per se, but there are often specific fields in
projects that I’ve found to be very useful in roadmapping discussions. Those
are:</p>

<ul>
  <li>The business impact of the milestone: senior leadership will often ask about
the cost-benefit of lowering the priority of specific tasks, and it’s helpful
to understand why this is valuable.</li>
  <li>Acceptance criteria: a good practice regardless of this post, but it’s
valuable to be crystal clear on <em>what</em> you’re planning on delivering, and how
to validate it has been delivered. It often discovers gaps in understanding or
expectations.</li>
  <li>A target delivery date: if there is a hard due date, it’s valuable to specify
that.</li>
  <li>An effort or wall time estimate, in a unit of time: this helps you calculate
the actual time it would take to deliver something, based on the target date
of a tasks’s dependencies.</li>
</ul>

<h3 id="specify-a-target-date-or-calculate-based-on-dependencies">Specify a target date, or calculate based on dependencies.</h3>

<p>A big issue with cross-organizational planning is figuring out how long it will
actually take to deliver something. In an ideal model, the actual delivery
date of something is the sum of the duration of current task, and the sum or the
delivery dates of all of the upstream dependencies that will take the longest.</p>

<p>Therefore, two pieces of information are necessary to calculate such a date:</p>

<ul>
  <li>The duration of the actual task (also known as effort, cost, or other names).</li>
  <li>The estimated delivery date. for example, an external dependency on a vendor,
or hardware with target date at which it will finish being constructed. These
commitments are generally dates, not based on some effort estimate.</li>
</ul>

<h3 id="make-project-trackers-fast">Make project trackers fast</h3>

<p>The biggest killer to project management trackers is the speed or friction it
takes to update them. If changing a single field requires five steps, or a page
load takes a long time, those will both completely disincentivize people to fill
things in as they go. Speed is a common reason I’ve heard, discussing the ideas
in this blog post with colleagues.</p>

<p>Due to similar friction I’ve faced with documents anod knowledge bases, I just
keep a bunch of markdown document in a folder for my notes. I opened it with
VSCode so I can easily jot down notes - this is vastly faster than any web-based
solution I’ve found, and I’m more likely to take good notes as a result.</p>

<h2 id="existing-challenges">Existing Challenges</h2>

<p>These patterns above provide a great structure for organizing this knowledge.
However, this alone is not a complete solution for a well organized project.</p>

<p>I’ve enumerated some of the challenges below.</p>

<h3 id="keeping-task-metadata-up-to-date">Keeping task metadata up to date</h3>

<p>Like any semi-automated system, the above is only valuable if the data is up to
date. In my experience, individual contributors like doing the work, but do not
like rotely filling in updates in project trackers.</p>

<p>Some patterns I’ve seen work, albeit sub-optimal:</p>

<ul>
  <li>Have a single project manager be responsible for ensuring tickets are up to
date. Have a regular sync meeting where individuals give updates and update
the project tracker live.</li>
  <li>Communal updates: whoever happens to ask the question also helps update the
tickets. This is not 100% effective, but does ensure that some updates occur.</li>
  <li>Have a dedicated time, with a program / project manager as a driver, to ask
everyone to update their issues.</li>
  <li>Make it so that the issues are the <em>only</em> way to update management on the
progress of a task: the forcing function will build the habit.</li>
</ul>

<p>Again, none of these are completely effective, but do help.</p>

<h3 id="enabling-deeper-roadmap-discussions">Enabling deeper roadmap discussions</h3>

<p>One reason I believe people gravitate toward ad-hoc planning documents is
because of how the document format (with some commenting infrastructure) allows
for great long-form discussion.</p>

<p>Task tracking is traditionally quite bad at this - you can’t go comment on a
specific aspect of an issue (e.g. one or two lines in it’s description), it’s
hard to see the project overall without going to some other format like a
spreadsheet, which may not sync data back upstream.</p>

<p>At some point, project trackers should start to support this use case.</p>

<h2 id="other-thoughts">Other thoughts</h2>

<h3 id="issue-tracker-should-use-a-global-id-not-namespace-by-project">Issue tracker should use a global id, not namespace by project</h3>

<p>Issue trackers like Jira namespace their issues with a project space (e.g.
PRJ-001). I think a single global id is better, perhaps a sequential,
monotonically increasing integer (e.g. Google buganizer). The metadata for which
project an issue belongs to can live in some other field.</p>

<p>The reasoning is:</p>

<ul>
  <li>It’s easy to move issues from one team to another: links don’t break as
renames happen, you don’t need to keep a table of old ids on the server side.</li>
  <li>It’s straightforward to link issues to another: you don’t need to know which
project it was in.</li>
  <li>It simplifies any linking metadata, to have all issues in the same format
(e.g. pattern matching for APIs and what not).</li>
</ul>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>I’ll be updating this periodically with some more thoughts, but I’d love to hear
feedback on these patterns if you try them, or let me know about one what works
for you!</p>]]></content><author><name></name></author><category term="coding" /><category term="project-management" /><summary type="html"><![CDATA[Design patterns for organizing multi-organization Projects]]></summary></entry></feed>